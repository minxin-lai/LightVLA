## æ¨¡å— 1: è®­ç»ƒå…¥å£ä¸é…ç½® ([train.py](cci:7://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/vla-scripts/train.py:0:0-0:0))

### ğŸ“ å…¥å£å‡½æ•°ä½ç½®
**æ–‡ä»¶**ï¼š[vla-scripts/train.py](cci:7://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/vla-scripts/train.py:0:0-0:0)  
**å…¥å£å‡½æ•°**ï¼šç¬¬ 717-718 è¡Œçš„ [train(cfg: TrainingConfig)](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/vla-scripts/train.py:716:0-1095:17) å‡½æ•°

```python
@draccus.wrap()
def train(cfg: TrainingConfig) -> None:
```

### ğŸ”§ é…ç½®ç±» [TrainingConfig](cci:2://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/vla-scripts/train.py:66:0-110:13)ï¼ˆç¬¬ 67-111 è¡Œï¼‰

è¿™æ˜¯è®­ç»ƒçš„æ ¸å¿ƒé…ç½®ï¼Œå®šä¹‰äº†æ‰€æœ‰è¶…å‚æ•°ï¼š

| å‚æ•° | é»˜è®¤å€¼ | å«ä¹‰ |
|------|--------|------|
| `vla_path` | `"openvla/openvla-7b"` | é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ï¼ˆHuggingFace Hub æˆ–æœ¬åœ°ï¼‰ |
| `data_root_dir` | `datasets/rlds` | RLDS æ ¼å¼æ•°æ®é›†æ ¹ç›®å½• |
| `dataset_name` | `"aloha_scoop_x_into_bowl"` | è¦è®­ç»ƒçš„æ•°æ®é›†åç§° |
| `use_l1_regression` | `True` | **é»˜è®¤å¯ç”¨ L1 å›å½’**ï¼ˆè¿ç»­åŠ¨ä½œé¢„æµ‹ï¼‰ |
| `use_diffusion` | `False` | æ˜¯å¦ç”¨ diffusion é¢„æµ‹åŠ¨ä½œ |
| `num_images_in_input` | `1` | è¾“å…¥å›¾åƒæ•°é‡ï¼ˆ1=å•å›¾ï¼Œ2=å•å›¾+æ‰‹è…•ç›¸æœºï¼‰ |
| `batch_size` | `16` | æ¯ä¸ª GPU çš„ batch size |
| `max_steps` | `100000` | æœ€å¤§è®­ç»ƒæ­¥æ•° |

### ğŸš€ è®­ç»ƒå¯åŠ¨æµç¨‹æ¦‚è¿°

[train()](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/vla-scripts/train.py:716:0-1095:17) å‡½æ•°æŒ‰ä»¥ä¸‹é¡ºåºæ‰§è¡Œï¼š

```
1. GPU è®¾ç½® & åˆ†å¸ƒå¼åˆå§‹åŒ– (ç¬¬ 738-741 è¡Œ)
        â†“
2. åŠ è½½ Processor + VLA æ¨¡å‹ (ç¬¬ 796-803 è¡Œ)
        â†“
3. è®¾ç½®è¾“å…¥å›¾åƒæ•°é‡ (ç¬¬ 808 è¡Œ)
   vla.set_num_images_in_input(cfg.num_images_in_input)
        â†“
4. [å¯é€‰] å¯ç”¨ FiLM (ç¬¬ 811-825 è¡Œ)
        â†“
5. DDP åŒ…è£…æ¨¡å‹ (ç¬¬ 828 è¡Œ)
        â†“
6. åˆå§‹åŒ– Action Head (ç¬¬ 841-868 è¡Œ)
   - L1 å›å½’å¤´ æˆ– Diffusion å¤´
        â†“
7. è·å– patch æ•°é‡ (ç¬¬ 871 è¡Œ)
   NUM_PATCHES = vla.module.get_num_patches()
        â†“
8. åˆ›å»ºä¼˜åŒ–å™¨ + å­¦ä¹ ç‡è°ƒåº¦å™¨ (ç¬¬ 880-898 è¡Œ)
        â†“
9. åŠ è½½æ•°æ®é›† + DataLoader (ç¬¬ 903-973 è¡Œ)
        â†“
10. è®­ç»ƒå¾ªç¯å¼€å§‹ (ç¬¬ 985-1090 è¡Œ)
```

### â­ LightVLA ç‹¬æœ‰æ”¹åŠ¨

åœ¨ç¬¬ 993 è¡Œï¼ŒLightVLA åŠ å…¥äº†ä¸€è¡Œå…³é”®ä»£ç ï¼š

```python
vla.module.language_model.model.pruner.set_noise_scale(1 - log_step / cfg.max_steps)
```

**è§£é‡Š**ï¼š
- è¿™æ˜¯ **LightVLA çš„å™ªå£°è°ƒåº¦**
- Prunerï¼ˆå‰ªæå™¨ï¼‰åœ¨è®­ç»ƒæ—¶éœ€è¦æ¢ç´¢å™ªå£°ï¼Œå™ªå£°ä» 1.0 **çº¿æ€§è¡°å‡åˆ° 0**
- `log_step=0` æ—¶ï¼Œ`noise_scale=1.0`ï¼ˆæœ€å¤§æ¢ç´¢ï¼‰
- `log_step=max_steps` æ—¶ï¼Œ`noise_scale=0`ï¼ˆæ— å™ªå£°ï¼Œçº¯å­¦åˆ°çš„ç­–ç•¥ï¼‰

---

### ğŸ¯ å…³é”®ç‚¹æ€»ç»“

1. **å…¥å£**ï¼š[train(cfg: TrainingConfig)](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/vla-scripts/train.py:716:0-1095:17) æ˜¯æ•´ä¸ªè®­ç»ƒçš„èµ·ç‚¹
2. **é…ç½®é©±åŠ¨**ï¼šé€šè¿‡ [TrainingConfig](cci:2://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/vla-scripts/train.py:66:0-110:13) çš„å‚æ•°æ§åˆ¶è®­ç»ƒè¡Œä¸º
3. **æ¨¡å‹åŠ è½½**ï¼šä» `cfg.vla_path` åŠ è½½ `OpenVLAForActionPrediction`
4. **LightVLA ç‰¹è‰²**ï¼šå™ªå£°è°ƒåº¦ `set_noise_scale()` æ˜¯ LightVLA ç‹¬æœ‰çš„

---

**ä¸‹ä¸€ä¸ªæ¨¡å—**æˆ‘ä¼šè®²è§£ï¼š**æ¨¡å‹åŠ è½½ä¸ `OpenVLAForActionPrediction` ç±»**â€”â€”ä¹Ÿå°±æ˜¯ VLA æ¨¡å‹æ˜¯å¦‚ä½•æ„å»ºçš„ã€‚



---

## æ¨¡å— 2: VLA æ¨¡å‹åŠ è½½ä¸æ¶æ„ ([OpenVLAForActionPrediction](cci:2://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:1041:0-1402:52))

### ğŸ“ æ¨¡å‹åŠ è½½ä½ç½®
**æ–‡ä»¶**ï¼š[vla-scripts/train.py](cci:7://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/vla-scripts/train.py:0:0-0:0) ç¬¬ 796-803 è¡Œ

```python
processor = PrismaticProcessor.from_pretrained(cfg.vla_path, trust_remote_code=True)
vla = OpenVLAForActionPrediction.from_pretrained(
    cfg.vla_path,
    torch_dtype=torch.bfloat16,
    device_map=device_id,
    low_cpu_mem_usage=True,
    trust_remote_code=True,
)
```

### ğŸ—ï¸ VLA æ¨¡å‹ç±»ç»§æ‰¿å…³ç³»

```
PrismaticPreTrainedModel (HuggingFace åŸºç±»)
        â”‚
        â†“
PrismaticForConditionalGeneration  â† æ ¸å¿ƒ VLM å®ç°
        â”‚
        â†“
OpenVLAForActionPrediction  â† åŠ¨ä½œé¢„æµ‹å°è£…
```

**æ–‡ä»¶ä½ç½®**ï¼š[prismatic/extern/hf/modeling_prismatic.py](cci:7://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:0:0-0:0)

---

### ğŸ”§ `PrismaticForConditionalGeneration.__init__()` ï¼ˆç¬¬ 640-682 è¡Œï¼‰

è¿™æ˜¯ VLM æ¨¡å‹çš„**æ ¸å¿ƒæ„å»ºå‡½æ•°**ï¼š

```python
def __init__(self, config: PrismaticConfig) -> None:
    super().__init__(config)
    
    # 1ï¸âƒ£ åˆ›å»ºè§†è§‰ backbone
    self.vision_backbone = PrismaticVisionBackbone(...)
    
    # 2ï¸âƒ£ åˆ›å»ºæŠ•å½±å™¨ (vision â†’ language ç©ºé—´)
    self.projector = PrismaticProjector(...)
    
    # 3ï¸âƒ£ â­ LightVLA å…³é”®æ”¹åŠ¨ï¼šåˆ›å»ºå¸¦ Pruner çš„ LLM
    num_patches = self.vision_backbone.get_num_patches() * self.vision_backbone.get_num_images_in_input()
    self.language_model = PrunedLlamaForCausalLM(config.text_config, num_patches)
```

### ğŸ†š OpenVLA-OFT vs LightVLA çš„å…³é”®åŒºåˆ«

| ç»„ä»¶ | OpenVLA-OFT | LightVLA |
|------|-------------|----------|
| LLM | `AutoModelForCausalLM.from_config(...)` | [PrunedLlamaForCausalLM(config, num_patches)](cci:2://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:263:0-363:9) |
| å‰ªæå™¨ | âŒ æ—  | âœ… å†…ç½® [TokenPruner](cci:2://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:48:0-135:51) |
| ç¡¬ç»‘å®š | æ”¯æŒä»»æ„ HF CausalLM | **åªæ”¯æŒ Llama æ¶æ„** |

**ç¬¬ 676 è¡Œ**æ˜¯ LightVLA çš„å…³é”®æ”¹åŠ¨ï¼š
```python
self.language_model = PrunedLlamaForCausalLM(config.text_config, num_patches)
```

---

### ğŸ“ ä¸‰å¤§ç»„ä»¶è¯¦è§£

#### 1ï¸âƒ£ [PrismaticVisionBackbone](cci:2://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:389:0-549:48)ï¼ˆç¬¬ 390-550 è¡Œï¼‰

**åŠŸèƒ½**ï¼šä»å›¾åƒæå– patch features

```
pixel_values (B, C, H, W)
        â†“
   TIMM ViT (SigLIP/DINOv2)
        â†“
patch_features (B, P, D_vision)
```

- **å• backbone**ï¼š[(B, 3, H, W)](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/vla-scripts/train.py:716:0-1095:17) â†’ [(B, P, D)](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/vla-scripts/train.py:716:0-1095:17)
- **Fused backbone**ï¼ˆåŒ ViTï¼‰ï¼š[(B, 6, H, W)](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/vla-scripts/train.py:716:0-1095:17) â†’ SigLIP + DINOv2 â†’ æ‹¼æ¥ hidden dim

**å¤šå›¾è¾“å…¥**ï¼ˆç¬¬ 529-550 è¡Œï¼‰ï¼š
- 2 å›¾ + fused â†’ `pixel_values` å½¢çŠ¶ [(B, 12, H, W)](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/vla-scripts/train.py:716:0-1095:17)ï¼ˆæ¯å›¾ 6 é€šé“ï¼‰
- è¾“å‡ºï¼špatch åœ¨ dim=1 æ‹¼æ¥

---

#### 2ï¸âƒ£ [PrismaticProjector](cci:2://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:553:0-584:33)ï¼ˆç¬¬ 553-585 è¡Œï¼‰

**åŠŸèƒ½**ï¼šå°†è§†è§‰ç‰¹å¾æŠ•å½±åˆ° LLM çš„éšè—ç©ºé—´

```python
# é fused æ¨¡å¼ï¼ˆ2 å±‚ MLPï¼‰
vision_dim â†’ llm_dim â†’ llm_dim

# fused æ¨¡å¼ï¼ˆ3 å±‚ MLPï¼‰
vision_dim â†’ 4*vision_dim â†’ llm_dim â†’ llm_dim
```

**ä¾‹å­**ï¼š`2176 â†’ 8704 â†’ 4096 â†’ 4096`ï¼ˆå½“ fused ä¸” `vision_dim=2176`ï¼‰

---

#### 3ï¸âƒ£ [PrunedLlamaForCausalLM](cci:2://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:263:0-363:9)ï¼ˆLightVLA ç‹¬æœ‰ï¼‰

è¿™æ˜¯**ä¸‹ä¸€ä¸ªæ¨¡å—**è¦è¯¦ç»†è®²çš„ï¼Œæ˜¯ LightVLA çš„æ ¸å¿ƒæ”¹åŠ¨æ‰€åœ¨ã€‚

---

### ğŸ”„ `OpenVLAForActionPrediction.set_num_images_in_input()`ï¼ˆç¬¬ 1056-1058 è¡Œï¼‰

```python
def set_num_images_in_input(self, num_images_in_input):
    self.vision_backbone.set_num_images_in_input(num_images_in_input)
    # â­ LightVLA ç‹¬æœ‰ï¼šåŒæ­¥æ›´æ–° pruner çš„ num_patches
    self.language_model.model.pruner.num_patches = (
        self.vision_backbone.get_num_patches() * 
        self.vision_backbone.get_num_images_in_input()
    )
```

**âš ï¸ é‡è¦**ï¼šLightVLA å¿…é¡»é€šè¿‡ `vla.set_num_images_in_input()` è®¾ç½®å›¾åƒæ•°é‡ï¼Œä¸èƒ½åªæ”¹ `vision_backbone`ã€‚å› ä¸º **Pruner éœ€è¦çŸ¥é“ patch æ•°é‡**æ‰èƒ½æ­£ç¡®åˆ‡åˆ†åºåˆ—ã€‚

---

### ğŸ¯ å…³é”®ç‚¹æ€»ç»“

1. **æ¨¡å‹ç»“æ„**ï¼š`è§†è§‰ backbone` + `æŠ•å½±å™¨` + `è¯­è¨€æ¨¡å‹`
2. **LightVLA æ”¹åŠ¨**ï¼šç”¨ [PrunedLlamaForCausalLM](cci:2://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:263:0-363:9) æ›¿æ¢ `AutoModelForCausalLM`
3. **num_patches åŒæ­¥**ï¼š[set_num_images_in_input()](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:1055:4-1057:142) å¿…é¡»åŒæ—¶æ›´æ–° pruner
4. **ç¡¬ç»‘å®š Llama**ï¼šLightVLA åªæ”¯æŒ Llama æ¶æ„

---

**ä¸‹ä¸€ä¸ªæ¨¡å—**æˆ‘ä¼šè®²è§£ï¼š**å¤šæ¨¡æ€ Forward æ•°æ®æµ**â€”â€”ä¹Ÿå°±æ˜¯ `pixel_values` + `input_ids` æ˜¯å¦‚ä½•æ‹¼æ¥å¹¶é€å…¥ LLM çš„ã€‚



---

## æ¨¡å— 3: å¤šæ¨¡æ€ Forward æ•°æ®æµ

### ğŸ“ æ ¸å¿ƒå‡½æ•°ä½ç½®
**æ–‡ä»¶**ï¼š[prismatic/extern/hf/modeling_prismatic.py](cci:7://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:0:0-0:0)  
**å‡½æ•°**ï¼š`PrismaticForConditionalGeneration.forward()`ï¼ˆç¬¬ 821-997 è¡Œï¼‰

è¿™æ˜¯ VLA æ¨¡å‹çš„**æ ¸å¿ƒå‰å‘ä¼ æ’­**ï¼Œè´Ÿè´£å°†è§†è§‰å’Œè¯­è¨€ä¿¡æ¯èåˆã€‚

---

### ğŸ§© Forward çš„ä¸‰ç§æ¨¡å¼

```python
def forward(self, input_ids, attention_mask, pixel_values, labels, ...):
    
    # æ¨¡å¼ 1: ç¼“å­˜ç”Ÿæˆï¼ˆæ¨ç†æ—¶è‡ªå›å½’ï¼‰
    if input_ids.shape[1] == 1:
        ...  # ç¬¬ 856-872 è¡Œ
    
    # æ¨¡å¼ 2: çº¯è¯­è¨€ï¼ˆæ— å›¾åƒï¼‰
    elif pixel_values is None:
        ...  # ç¬¬ 875-890 è¡Œ
    
    # æ¨¡å¼ 3: å¤šæ¨¡æ€ï¼ˆå›¾åƒ + è¯­è¨€ï¼‰â† è®­ç»ƒæ—¶èµ°è¿™æ¡è·¯
    elif input_ids.shape[0] == pixel_values.shape[0]:
        ...  # ç¬¬ 893-965 è¡Œ
```

æˆ‘ä»¬é‡ç‚¹è®²è§£**æ¨¡å¼ 3ï¼šå¤šæ¨¡æ€ forward**ã€‚

---

### ğŸ”„ å¤šæ¨¡æ€ Forward å®Œæ•´æ•°æ®æµï¼ˆç¬¬ 893-965 è¡Œï¼‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      è¾“å…¥æ•°æ®                                â”‚
â”‚  input_ids: (B, S_text)     pixel_values: (B, C, H, W)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 1: è·å–æ–‡æœ¬ embeddingï¼ˆç¬¬ 897 è¡Œï¼‰                     â”‚
â”‚  input_embeddings = self.get_input_embeddings()(input_ids)  â”‚
â”‚  å½¢çŠ¶: (B, S_text, D)                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 2: æå– action maskï¼ˆç¬¬ 900 è¡Œï¼‰                       â”‚
â”‚  all_actions_mask = _process_action_masks(labels)           â”‚
â”‚  ç”¨äºè¯†åˆ«å“ªäº›ä½ç½®æ˜¯ action token                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 3: è§†è§‰ç‰¹å¾æå– + æŠ•å½±ï¼ˆç¬¬ 908 è¡Œï¼‰                     â”‚
â”‚  projected_patch_embeddings = _process_vision_features(...)  â”‚
â”‚  å½¢çŠ¶: (B, P, D)  å…¶ä¸­ P = num_patches * num_images          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 4: [å¯é€‰] æ·»åŠ  proprio / diffusion timestepï¼ˆç¬¬ 911-920ï¼‰â”‚
â”‚  projected_patch_embeddings = cat([patches, proprio], dim=1) â”‚
â”‚  projected_patch_embeddings = cat([patches, timestep], dim=1)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 5: å¤„ç† action embeddingsï¼ˆç¬¬ 922-943 è¡Œï¼‰             â”‚
â”‚  if noisy_actions:  # Diffusion æ¨¡å¼                        â”‚
â”‚      â†’ ç”¨ noisy action features æ›¿æ¢ action ä½ç½®çš„ embedding â”‚
â”‚  else:  # L1 å›å½’æ¨¡å¼                                       â”‚
â”‚      â†’ æŠŠ action ä½ç½®çš„ embedding æ¸…é›¶                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 6: â­ å¤šæ¨¡æ€æ‹¼æ¥ï¼ˆç¬¬ 946-948 è¡Œï¼‰                       â”‚
â”‚  multimodal_embeddings = cat([                              â”‚
â”‚      BOS,              # input_embeddings[:, :1, :]         â”‚
â”‚      patches,          # projected_patch_embeddings         â”‚
â”‚      text/action       # input_embeddings[:, 1:, :]         â”‚
â”‚  ], dim=1)                                                  â”‚
â”‚  å½¢çŠ¶: (B, 1 + P + S_text-1, D)                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 7: é€å…¥ LLMï¼ˆç¬¬ 954-965 è¡Œï¼‰                           â”‚
â”‚  language_model_output = self.language_model(               â”‚
â”‚      inputs_embeds=multimodal_embeddings,                   â”‚
â”‚      attention_mask=multimodal_attention_mask,              â”‚
â”‚  )                                                          â”‚
â”‚  â­ LightVLA åœ¨è¿™é‡Œå†…éƒ¨ä¼šè°ƒç”¨ TokenPruner                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### â­ å…³é”®å‡½æ•°ï¼š[_build_multimodal_attention()](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:782:4-805:63)ï¼ˆç¬¬ 783-806 è¡Œï¼‰

è¿™æ˜¯**è§†è§‰ token æ’å…¥çš„æ ¸å¿ƒé€»è¾‘**ï¼š

```python
def _build_multimodal_attention(self, input_embeddings, projected_patch_embeddings, attention_mask):
    # æ„å»ºå¤šæ¨¡æ€åºåˆ—ï¼š[BOS] + [è§†è§‰ patches] + [æ–‡æœ¬/åŠ¨ä½œ tokens]
    multimodal_embeddings = torch.cat(
        [input_embeddings[:, :1, :],        # BOS token
         projected_patch_embeddings,         # è§†è§‰ patches
         input_embeddings[:, 1:, :]],        # å‰©ä½™æ–‡æœ¬
        dim=1
    )
    # attention mask ä¹ŸåšåŒæ ·å¤„ç†
    ...
    return multimodal_embeddings, multimodal_attention_mask
```

**æœ€ç»ˆåºåˆ—å¸ƒå±€**ï¼š
```
ä½ç½®:    0       1 ... P       P+1 ... P+S_text
å†…å®¹: [BOS] [PATCH_1 ... PATCH_P] [TEXT/ACTION tokens]
```

---

### ğŸ”§ Action Token å¤„ç†ï¼ˆç¬¬ 922-943 è¡Œï¼‰

è¿™æ®µé€»è¾‘å†³å®šäº† **action token çš„ embedding æ€ä¹ˆå¤„ç†**ï¼š

```python
if noisy_actions is not None:
    # Diffusion æ¨¡å¼ï¼šç”¨ noisy action features æ›¿æ¢
    noisy_action_features = noisy_action_projector(noisy_actions)
    input_embeddings = self._replace_input_embeddings(
        input_embeddings, all_actions_mask, noisy_action_features
    )
else:
    # L1 å›å½’æ¨¡å¼ï¼šaction ä½ç½®æ¸…é›¶
    input_embeddings = input_embeddings * ~all_actions_mask
```

**âš ï¸ æ³¨æ„**ï¼šè¿™ä¸æ˜¯ LightVLA ç‹¬æœ‰çš„ï¼ŒOpenVLA-OFT ä¹Ÿæœ‰è¿™ä¸ªé€»è¾‘ã€‚LightVLA çš„å·®åˆ«åœ¨äº **LLM å†…éƒ¨ä¼šä¸ä¼šå‰ªæ‰è§†è§‰ patch token**ã€‚

---

### ğŸ“Š çœŸå®å¼ é‡å½¢çŠ¶ç¤ºä¾‹

å‡è®¾ï¼š
- fused + 2 å›¾ï¼šæ¯å›¾ `P_img=256`ï¼Œæ€» patch æ•° `P=512`
- æ–‡æœ¬ + actionï¼š`S_text=80`
- LLM hidden sizeï¼š`D=4096`

| é˜¶æ®µ | å¼ é‡å | å½¢çŠ¶ |
|------|--------|------|
| è§†è§‰æå–å | `patch_features` | [(B, 512, 2176)](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/vla-scripts/train.py:716:0-1095:17) |
| æŠ•å½±å | `projected_patch_embeddings` | [(B, 512, 4096)](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/vla-scripts/train.py:716:0-1095:17) |
| æ–‡æœ¬ embedding | [input_embeddings](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:687:4-688:55) | [(B, 80, 4096)](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/vla-scripts/train.py:716:0-1095:17) |
| æ‹¼æ¥å | `multimodal_embeddings` | [(B, 1+512+79, 4096)](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/vla-scripts/train.py:716:0-1095:17) = [(B, 592, 4096)](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/vla-scripts/train.py:716:0-1095:17) |

---

### ğŸ¯ å…³é”®ç‚¹æ€»ç»“

1. **åºåˆ—å¸ƒå±€å›ºå®š**ï¼š`[BOS] + [è§†è§‰ patches] + [æ–‡æœ¬/åŠ¨ä½œ]`
2. **è§†è§‰æ’å…¥ç‚¹**ï¼šåœ¨ BOS ä¹‹åã€æ–‡æœ¬ä¹‹å‰
3. **Action å¤„ç†**ï¼šL1 æ¨¡å¼æ¸…é›¶ï¼ŒDiffusion æ¨¡å¼ç”¨ noisy features æ›¿æ¢
4. **é€å…¥ LLM**ï¼š`multimodal_embeddings` ä½œä¸º `inputs_embeds` ä¼ å…¥
5. **LightVLA åŒºåˆ«**ï¼šLLM å†…éƒ¨ä¼šè°ƒç”¨ [TokenPruner](cci:2://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:48:0-135:51)ï¼ˆä¸‹ä¸€æ¨¡å—è®²è§£ï¼‰

---

**ä¸‹ä¸€ä¸ªæ¨¡å—**æˆ‘ä¼šè®²è§£ï¼š**TokenPruner å‰ªæå™¨**â€”â€”LightVLA çš„æ ¸å¿ƒåˆ›æ–°ï¼Œè§£é‡Šå®ƒå¦‚ä½•åœ¨ LLM å†…éƒ¨å¯¹è§†è§‰ patch token è¿›è¡ŒåŠ¨æ€å‰ªæã€‚

### 

ä¸æ˜¯åº”è¯¥è®²è§£OpenVLAForActionPredictionè¿™ä¸ªç±»å—ï¼Ÿ
_process_action_masksæ˜¯å¹²å˜›çš„ï¼Ÿ
proprioæ˜¯ä»€ä¹ˆï¼Ÿ

### 

è¯¦ç»†å›ç­”ä½ çš„ä¸‰ä¸ªé—®é¢˜ï¼Œå¹¶è¡¥å……è®²è§£ [OpenVLAForActionPrediction](cci:2://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:1041:0-1402:52) ç±»ã€‚

---

## æ¨¡å— 3ï¼ˆè¡¥å……ï¼‰ï¼š[OpenVLAForActionPrediction](cci:2://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:1041:0-1402:52) ç±»è¯¦è§£

### ğŸ“ ç±»ä½ç½®
**æ–‡ä»¶**ï¼š[prismatic/extern/hf/modeling_prismatic.py](cci:7://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:0:0-0:0)  
**ç±»å®šä¹‰**ï¼šç¬¬ 1042-1200+ è¡Œ

---

### â“ é—®é¢˜ 1ï¼š[_process_action_masks](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:752:4-757:31) æ˜¯å¹²å˜›çš„ï¼Ÿ

**å®šä¹‰ä½ç½®**ï¼š[modeling_prismatic.py](cci:7://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:0:0-0:0) ç¬¬ 753-758 è¡Œ

```python
def _process_action_masks(self, labels):
    current_action_mask = get_current_action_mask(labels)  # å½“å‰åŠ¨ä½œçš„ mask
    next_actions_mask = get_next_actions_mask(labels)      # æœªæ¥åŠ¨ä½œçš„ mask
    all_actions_mask = current_action_mask | next_actions_mask  # åˆå¹¶
    return all_actions_mask
```

**æ ¸å¿ƒå‡½æ•°**ï¼ˆ[train_utils.py](cci:7://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/training/train_utils.py:0:0-0:0) ç¬¬ 8-22 è¡Œï¼‰ï¼š

```python
def get_current_action_mask(token_ids):
    # æ‰¾å‡ºé IGNORE_INDEX çš„ä½ç½®
    newline_positions = token_ids != IGNORE_INDEX
    cumsum = torch.cumsum(newline_positions, dim=1)
    
    # ç¬¬ 1 åˆ° ACTION_DIM ä¸ªæœ‰æ•ˆ token æ˜¯"å½“å‰åŠ¨ä½œ"
    mask = (1 <= cumsum) & (cumsum <= ACTION_DIM)
    
    # åªä¿ç•™ action tokenï¼ˆtoken_id > ACTION_TOKEN_BEGIN_IDXï¼‰
    action_tokens_only_mask = token_ids > ACTION_TOKEN_BEGIN_IDX
    return action_tokens_only_mask * mask
```

**å›¾è§£**ï¼šå‡è®¾ `ACTION_DIM=7`ï¼Œåºåˆ—å¸ƒå±€å¦‚ä¸‹ï¼š

```
labels:  [-100, -100, ..., -100, A1, A2, A3, A4, A5, A6, A7, A8, ..., A56, STOP]
                                 â†‘------------------------â†‘
                                 current_action (ç¬¬1-7ä¸ª)
                                                           â†‘---------------â†‘
                                                           next_actions (ç¬¬8-56ä¸ª)
```

**ä½œç”¨**ï¼š
- **è¯†åˆ« action token çš„ä½ç½®**ï¼šç”¨äºåœ¨ L1 å›å½’æ¨¡å¼ä¸‹æ¸…é›¶è¿™äº›ä½ç½®çš„ embedding
- **è®¡ç®— loss**ï¼šåªåœ¨ action ä½ç½®è®¡ç®—å›å½’æŸå¤±

---

### â“ é—®é¢˜ 2ï¼š[proprio](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:770:4-780:41) æ˜¯ä»€ä¹ˆï¼Ÿ

**[proprio](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:770:4-780:41) = Proprioceptionï¼ˆæœ¬ä½“æ„Ÿè§‰ï¼‰= æœºå™¨äººçš„å†…éƒ¨çŠ¶æ€**

**å®šä¹‰ä½ç½®**ï¼š[prismatic/vla/constants.py](cci:7://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/vla/constants.py:0:0-0:0) ç¬¬ 26-44 è¡Œ

| å¹³å° | `PROPRIO_DIM` | åŒ…å«å†…å®¹ |
|------|---------------|----------|
| **LIBERO** | 8 | 7 ä¸ªå…³èŠ‚ä½ç½® + 1 ä¸ªå¤¹çˆªçŠ¶æ€ |
| **ALOHA** | 14 | 14 ä¸ªå…³èŠ‚ä½ç½®ï¼ˆåŒè‡‚æœºå™¨äººï¼‰ |
| **BRIDGE** | 7 | 7 ä¸ªå…³èŠ‚ä½ç½® |

**åœ¨æ¨¡å‹ä¸­çš„ä½œç”¨**ï¼š

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     proprio (B, PROPRIO_DIM)    â”‚
                    â”‚  ä¾‹ï¼š[j1, j2, j3, j4, j5, j6, j7, gripper]
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    proprio_projector (MLP)       â”‚
                    â”‚    PROPRIO_DIM â†’ LLM_DIM         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚  proprio_features (B, 1, 4096)   â”‚
                    â”‚  ä½œä¸ºé¢å¤– token è¿½åŠ åˆ° patch åé¢  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**è®­ç»ƒæ—¶**ï¼ˆ[train.py](cci:7://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/vla-scripts/train.py:0:0-0:0) ç¬¬ 831-838 è¡Œï¼‰ï¼š

```python
if cfg.use_proprio:
    proprio_projector = init_module(
        ProprioProjector,
        "proprio_projector",
        cfg,
        device_id,
        {"llm_dim": vla.module.llm_dim, "proprio_dim": PROPRIO_DIM},
    )
```

**Forward æ—¶**ï¼ˆ[_process_proprio_features](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:770:4-780:41) ç¬¬ 771-781 è¡Œï¼‰ï¼š

```python
def _process_proprio_features(self, projected_patch_embeddings, proprio, proprio_projector):
    proprio_features = proprio_projector(proprio)  # (B, 1, LLM_DIM)
    # è¿½åŠ åˆ° patch åºåˆ—æœ«å°¾
    return torch.cat((projected_patch_embeddings, proprio_features), dim=1)
```

---

### ğŸ—ï¸ [OpenVLAForActionPrediction](cci:2://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:1041:0-1402:52) ç±»ç»“æ„

```python
class OpenVLAForActionPrediction(PrismaticForConditionalGeneration):
    
    def __init__(self, config):
        super().__init__(config)
        self.norm_stats = config.norm_stats    # åŠ¨ä½œå½’ä¸€åŒ–ç»Ÿè®¡é‡
        self.bins = np.linspace(-1, 1, 256)    # ç¦»æ•£åŒ– bins
        self.bin_centers = ...                  # bin ä¸­å¿ƒå€¼
        self.vocab_size = ...                   # è¯è¡¨å¤§å°
    
    # â­ LightVLA ç‹¬æœ‰ï¼šåŒæ­¥æ›´æ–° pruner
    def set_num_images_in_input(self, num_images_in_input):
        self.vision_backbone.set_num_images_in_input(num_images_in_input)
        self.language_model.model.pruner.num_patches = ...
    
    # æ¨ç†æ—¶å‡†å¤‡è¾“å…¥
    def _prepare_input_for_action_prediction(self, input_ids, attention_mask):
        # æ·»åŠ  ACTION_DIM * NUM_ACTIONS_CHUNK ä¸ªå ä½ç¬¦ token
        # æ·»åŠ  STOP token
        ...
    
    # åŠ¨ä½œåå½’ä¸€åŒ–
    def _unnormalize_actions(self, normalized_actions, unnorm_key):
        # ä» [-1, 1] æ˜ å°„å›çœŸå®åŠ¨ä½œç©ºé—´
        ...
    
    # Diffusion æ¨ç†
    def _run_diffusion_prediction(self, ...):
        # å¤šæ­¥å»å™ªç”ŸæˆåŠ¨ä½œ
        ...
    
    # ä¸»æ¨ç†æ¥å£
    def predict_action(self, ...):
        # ç«¯åˆ°ç«¯åŠ¨ä½œé¢„æµ‹
        ...
```

---

### ğŸ”‘ å…³é”®æ–¹æ³•

#### 1ï¸âƒ£ [_prepare_input_for_action_prediction](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:1062:4-1083:40)ï¼ˆç¬¬ 1063-1084 è¡Œï¼‰

**ä½œç”¨**ï¼šæ¨ç†æ—¶æ„é€ è¾“å…¥åºåˆ—

```python
# åŸå§‹ input_ids: [BOS, prompt_tokens...]
# æ·»åŠ å: [BOS, prompt_tokens..., action_placeholderÃ—56, STOP]

placeholder_action_token_ids = torch.ones((B, ACTION_DIM * NUM_ACTIONS_CHUNK))
input_ids = torch.cat([input_ids, placeholder_action_token_ids], dim=-1)
stop_token_id = torch.ones((B, 1)) * STOP_INDEX
input_ids = torch.cat([input_ids, stop_token_id], dim=-1)
```

**ä¸ºä»€ä¹ˆè¦åŠ å ä½ç¬¦ï¼Ÿ**
- L1 å›å½’æ¨¡å¼éœ€è¦**å›ºå®šä½ç½®**æ¥é¢„æµ‹åŠ¨ä½œ
- è¿™äº›ä½ç½®çš„ embedding ä¼šè¢«æ¸…é›¶ï¼ˆè®­ç»ƒæ—¶å­¦ä¼šå¿½ç•¥å®ƒä»¬ï¼‰
- LLM çš„ hidden states åœ¨è¿™äº›ä½ç½®ä¸Šè¾“å‡ºåŠ¨ä½œç‰¹å¾

---

### ğŸ¯ å…³é”®ç‚¹æ€»ç»“

| é—®é¢˜ | ç­”æ¡ˆ |
|------|------|
| [_process_action_masks](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:752:4-757:31) | æ‰¾å‡ºåºåˆ—ä¸­**å“ªäº›ä½ç½®æ˜¯ action token**ï¼Œç”¨äºæ¸…é›¶ embedding å’Œè®¡ç®— loss |
| [proprio](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:770:4-780:41) | æœºå™¨äººçš„**æœ¬ä½“æ„Ÿè§‰/å…³èŠ‚çŠ¶æ€**ï¼Œä½œä¸ºé¢å¤–è¾“å…¥è¿½åŠ åˆ°è§†è§‰ patch åé¢ |
| [OpenVLAForActionPrediction](cci:2://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:1041:0-1402:52) | å°è£…äº†**åŠ¨ä½œé¢„æµ‹ç›¸å…³é€»è¾‘**ï¼šè¾“å…¥å‡†å¤‡ã€åŠ¨ä½œåå½’ä¸€åŒ–ã€æ¨ç†æ¥å£ç­‰ |

---

**ä¸‹ä¸€ä¸ªæ¨¡å—**æˆ‘ä¼šè®²è§£ï¼š**TokenPruner å‰ªæå™¨**â€”â€”LightVLA çš„æ ¸å¿ƒåˆ›æ–°ã€‚





### User Input

current_action (ç¬¬1-7ä¸ª)å°±æ˜¯robot stateï¼Ÿå’Œproprioæ˜¯ä»€ä¹ˆå…³ç³»
next_actions (ç¬¬8-56ä¸ª)æ˜¯å ä½ç¬¦å—ï¼Ÿ

å’ŒçœŸæ­£è®­ç»ƒçš„æ—¶å€™æ˜¯ä»€ä¹ˆå…³ç³»ï¼Œè®­ç»ƒæ˜¯è¾“å…¥placeholder_action_token_idsè¿˜æ˜¯current_action+next_actionsï¼Ÿ



---

## ğŸ¯ å…³äº Action å’Œ Proprio çš„è¯¦ç»†è§£é‡Š

### â“ é—®é¢˜ 1ï¼š[current_action](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/training/train_utils.py:7:0-21:15) æ˜¯ robot state å—ï¼Ÿå’Œ proprio æ˜¯ä»€ä¹ˆå…³ç³»ï¼Ÿ

**ä¸æ˜¯ï¼** [current_action](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/training/train_utils.py:7:0-21:15) å’Œ [proprio](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:770:4-780:41) æ˜¯**å®Œå…¨ä¸åŒçš„æ¦‚å¿µ**ï¼š

| æ¦‚å¿µ | å®šä¹‰ | ä¾‹å­ï¼ˆLIBEROï¼‰ |
|------|------|----------------|
| **proprio** (æœ¬ä½“æ„Ÿè§‰) | æœºå™¨äºº**å½“å‰çš„çŠ¶æ€**ï¼ˆå…³èŠ‚ä½ç½®ã€å¤¹çˆªçŠ¶æ€ç­‰ï¼‰ | `[j1, j2, j3, j4, j5, j6, j7, gripper]` (8D) |
| **action** | æœºå™¨äºº**è¦æ‰§è¡Œçš„åŠ¨ä½œ**ï¼ˆå…³èŠ‚é€Ÿåº¦/ä½ç½®å˜åŒ–é‡ï¼‰ | `[Î”j1, Î”j2, ..., Î”j6, gripper_cmd]` (7D) |

**ç®€å•æ¯”å–»**ï¼š
- **proprio**ï¼šä½ ç°åœ¨åœ¨å“ªé‡Œï¼ˆå½“å‰ä½ç½®ï¼‰
- **action**ï¼šä½ è¦ç§»åŠ¨å¤šå°‘ï¼ˆç§»åŠ¨æŒ‡ä»¤ï¼‰

---

### â“ é—®é¢˜ 2ï¼š[next_actions](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/training/train_utils.py:24:0-38:15) æ˜¯å ä½ç¬¦å—ï¼Ÿ

**ä¸æ˜¯ï¼** åœ¨è®­ç»ƒæ—¶ï¼Œ[next_actions](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/training/train_utils.py:24:0-38:15) æ˜¯**çœŸå®çš„æœªæ¥åŠ¨ä½œ**ï¼Œä»æ•°æ®é›†ä¸­è¯»å–çš„ ground truthã€‚

è®©æˆ‘ç”¨ [RLDSBatchTransform](cci:2://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/vla/datasets/datasets.py:25:0-90:26)ï¼ˆç¬¬ 36-91 è¡Œï¼‰çš„ä»£ç æ¥è§£é‡Šï¼š

```python
def __call__(self, rlds_batch):
    # ä»æ•°æ®é›†è¯»å–çœŸå®çš„åŠ¨ä½œ
    current_action = rlds_batch["action"][0]   # ç¬¬ä¸€ä¸ªåŠ¨ä½œï¼ˆå½“å‰æ—¶åˆ»ï¼‰
    future_actions = rlds_batch["action"][1:]  # å‰©ä½™åŠ¨ä½œï¼ˆæœªæ¥æ—¶åˆ»ï¼‰
    
    # è½¬æ¢æˆ token å­—ç¬¦ä¸²
    current_action_string = self.action_tokenizer(current_action)  # ä¾‹å¦‚ 7 ä¸ª token
    future_actions_string = ''.join(self.action_tokenizer(future_actions))  # ä¾‹å¦‚ 49 ä¸ª token
    action_chunk_string = current_action_string + future_actions_string  # å…± 56 ä¸ª token
```

**æ•°æ®æ¥æº**ï¼ˆ[dataset.py](cci:7://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/vla/datasets/rlds/dataset.py:0:0-0:0) ç¬¬ 133 è¡Œï¼‰ï¼š
```python
traj_transform_kwargs=dict(
    window_size=1,                                   # å½“å‰å¸§ 1 ä¸ª
    future_action_window_size=NUM_ACTIONS_CHUNK-1,   # æœªæ¥å¸§ 7 ä¸ª (LIBERO: 8-1=7)
)
```

æ‰€ä»¥**è®­ç»ƒæ—¶**ï¼š
- `NUM_ACTIONS_CHUNK = 8`ï¼ˆLIBEROï¼‰
- [current_action](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/training/train_utils.py:7:0-21:15) = ç¬¬ 1 ä¸ªåŠ¨ä½œ
- [next_actions](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/training/train_utils.py:24:0-38:15) = ç¬¬ 2-8 ä¸ªåŠ¨ä½œ
- éƒ½æ˜¯**çœŸå®æ ‡ç­¾**ï¼Œä»çœŸå®æœºå™¨äººè½¨è¿¹æ•°æ®ä¸­è¯»å–

---

### â“ é—®é¢˜ 3ï¼šè®­ç»ƒ vs æ¨ç†çš„åŒºåˆ«

#### ğŸ“ **è®­ç»ƒæ—¶**

```
è¾“å…¥æ•°æ®ï¼ˆä»æ•°æ®é›†è¯»å–ï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  image: çœŸå®å›¾åƒ                                           â”‚
â”‚  proprio: [j1, j2, j3, j4, j5, j6, j7, gripper] (çœŸå®çŠ¶æ€)  â”‚
â”‚  actions: shape (8, 7) â† 8 ä¸ªæ—¶é—´æ­¥ï¼Œæ¯æ­¥ 7 ç»´åŠ¨ä½œ           â”‚
â”‚     â””â”€ action[0]: å½“å‰åŠ¨ä½œ (ground truth)                  â”‚
â”‚     â””â”€ action[1:8]: æœªæ¥åŠ¨ä½œ (ground truth)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
æ„é€  input_idsï¼ˆå«çœŸå® action tokensï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [BOS, prompt_tokens..., A1, A2, ..., A56, STOP]           â”‚
â”‚                         â†‘â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†‘                    â”‚
â”‚                    action tokens (çœŸå®æ ‡ç­¾ tokenized)       â”‚
â”‚                    = current_action + future_actions       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
Forward æ—¶ action embedding è¢«æ¸…é›¶ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  input_embeddings[action_mask] = 0                         â”‚
â”‚  (è™½ç„¶ input_ids æœ‰çœŸå® tokenï¼Œä½† embedding è¢«æ¸…é›¶)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
Loss è®¡ç®—ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ä» hidden_states ä¸­æå– action ä½ç½®                        â”‚
â”‚  ç”¨ action_head é¢„æµ‹è¿ç»­åŠ¨ä½œ                                â”‚
â”‚  L1 Loss = |predicted_action - ground_truth_action|        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### ğŸ¤– **æ¨ç†æ—¶**

```
è¾“å…¥ï¼ˆåªæœ‰å½“å‰è§‚å¯Ÿï¼‰ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  image: å½“å‰å›¾åƒ                                           â”‚
â”‚  proprio: å½“å‰æœºå™¨äººçŠ¶æ€ (å¯é€‰)                             â”‚
â”‚  prompt: "What action should the robot take to pick up...?" â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
_prepare_input_for_action_prediction() æ·»åŠ å ä½ç¬¦ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [BOS, prompt_tokens..., placeholderÃ—56, STOP]             â”‚
â”‚                         â†‘â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†‘                    â”‚
â”‚                    å ä½ç¬¦ token (å…¨æ˜¯ 1)                    â”‚
â”‚                    embedding ä¼šè¢«æ¸…é›¶                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
                               â–¼
Forward + predict_action()ï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ä» hidden_states ä¸­æå– action ä½ç½®                        â”‚
â”‚  ç”¨ action_head é¢„æµ‹è¿ç»­åŠ¨ä½œ                                â”‚
â”‚  åå½’ä¸€åŒ–å¾—åˆ°çœŸå®æœºå™¨äººåŠ¨ä½œ                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ğŸ“Š æ€»ç»“å¯¹æ¯”è¡¨

| åœºæ™¯ | `input_ids` ä¸­çš„ action | action embedding | ç›®çš„ |
|------|-------------------------|------------------|------|
| **è®­ç»ƒ** | çœŸå® action tokensï¼ˆä»æ•°æ®é›† tokenize å¾—åˆ°ï¼‰ | **æ¸…é›¶** | æä¾› labelsï¼Œè®¡ç®— loss |
| **æ¨ç†** | å ä½ç¬¦ tokensï¼ˆå…¨æ˜¯ 1ï¼‰ | **æ¸…é›¶** | æä¾›ä½ç½®ï¼Œé¢„æµ‹åŠ¨ä½œ |

**å…³é”®ç‚¹**ï¼š
- æ— è®ºè®­ç»ƒè¿˜æ˜¯æ¨ç†ï¼Œ**action ä½ç½®çš„ embedding éƒ½ä¼šè¢«æ¸…é›¶**
- è®­ç»ƒæ—¶éœ€è¦çœŸå® token æ˜¯å› ä¸º [labels](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:807:4-817:19) ç”¨äºè®¡ç®—ç¦»æ•£é¢„æµ‹çš„ lossï¼ˆè™½ç„¶ L1 æ¨¡å¼ä¸ç”¨ï¼‰
- æ¨ç†æ—¶ç”¨å ä½ç¬¦æ˜¯å› ä¸ºæ ¹æœ¬æ²¡æœ‰çœŸå®åŠ¨ä½œï¼Œåªéœ€è¦ä¸€ä¸ªä½ç½®æ¥è¾“å‡ºé¢„æµ‹

---

ä¸‹ä¸€ä¸ªæ¨¡å— **TokenPruner å‰ªæå™¨**~

### User Input

è®­ç»ƒçš„å…ˆæ„é€ äº†input_idsï¼Œé‡Œé¢å«æœ‰gtçš„æ•°æ®
ä½†æ˜¯åœ¨å‰å‘çš„æ—¶å€™ç”¨å ä½ç¬¦å»æ›¿æ¢äº†ï¼Ÿ
ç„¶ååœ¨åå‘ä¼ æ’­è®¡ç®—lossçš„æ—¶å€™gtçš„æ•°æ®å‚ä¸è®¡ç®—ï¼Ÿ
å…·ä½“ä»£ç åœ¨å“ªé‡Œ

---

## ğŸ” è®­ç»ƒæ—¶ Action æ•°æ®æµçš„å®Œæ•´ä»£ç è§£é‡Š

### ğŸ¯ ä½ ç†è§£å¾—å®Œå…¨æ­£ç¡®ï¼è®©æˆ‘ç”¨ä»£ç é€æ­¥ç¡®è®¤ï¼š

---

### ğŸ“Œ Step 1: æ•°æ®é›†æ„é€  `input_ids`ï¼ˆå« GT action tokensï¼‰

**ä½ç½®**ï¼š[prismatic/vla/datasets/datasets.py](cci:7://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/vla/datasets/datasets.py:0:0-0:0) ç¬¬ 36-76 è¡Œ

```python
def __call__(self, rlds_batch):
    # 1ï¸âƒ£ ä»æ•°æ®é›†è¯»å–çœŸå®åŠ¨ä½œ
    current_action = rlds_batch["action"][0]
    future_actions = rlds_batch["action"][1:]
    
    # 2ï¸âƒ£ ç”¨ action_tokenizer æŠŠåŠ¨ä½œè½¬æˆ token å­—ç¬¦ä¸²
    current_action_string = self.action_tokenizer(current_action)  # ä¾‹å¦‚ "â–1234â–5678..."
    future_actions_string = ''.join(self.action_tokenizer(future_actions))
    action_chunk_string = current_action_string + future_actions_string
    
    # 3ï¸âƒ£ æ„é€ å¯¹è¯ï¼ŒåŒ…å«çœŸå® action tokens
    conversation = [
        {"from": "human", "value": f"What action should the robot take to {lang}?"},
        {"from": "gpt", "value": action_chunk_string},  # â† çœŸå®åŠ¨ä½œ tokens
    ]
    
    # 4ï¸âƒ£ Tokenize æˆ input_ids
    input_ids = self.base_tokenizer(prompt_builder.get_prompt(), ...).input_ids
    labels = list(input_ids)  # â† labels å’Œ input_ids ç›¸åŒ
    
    # 5ï¸âƒ£ åªåœ¨ action ä½ç½®è®¡ç®— loss
    labels[: -(action_chunk_len + 1)] = IGNORE_INDEX  # é action ä½ç½®è®¾ä¸º -100
    
    return dict(input_ids=input_ids, labels=labels, actions=actions, ...)
```

**ç»“æœ**ï¼š
- `input_ids` = `[BOS, prompt, GT_action_tokens, STOP]`
- [labels](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:807:4-817:19) = `[-100, -100, ..., -100, GT_action_tokens, STOP]`
- [actions](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:1100:4-1119:22) = åŸå§‹è¿ç»­å€¼åŠ¨ä½œ [(8, 7)](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/vla/datasets/rlds/dataset.py:413:8-416:53) ç”¨äº L1 loss

---

### ğŸ“Œ Step 2: Forward æ—¶ action embedding è¢«**æ¸…é›¶**ï¼ˆä¸æ˜¯æ›¿æ¢ï¼‰

**ä½ç½®**ï¼š[prismatic/extern/hf/modeling_prismatic.py](cci:7://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:0:0-0:0) ç¬¬ 939-943 è¡Œ

```python
# åœ¨ PrismaticForConditionalGeneration.forward() ä¸­

# 1ï¸âƒ£ é¦–å…ˆè·å– input_embeddingsï¼ˆåŒ…å« GT action tokens çš„ embeddingï¼‰
input_embeddings = self.get_input_embeddings()(input_ids)  # (B, S, D)

# 2ï¸âƒ£ è·å– action ä½ç½®çš„ mask
all_actions_mask = self._process_action_masks(labels)  # å“ªäº›ä½ç½®æ˜¯ action token

# 3ï¸âƒ£ ğŸ”¥ å…³é”®ï¼šæ¸…é›¶ action ä½ç½®çš„ embedding
if noisy_actions is not None:
    # Diffusion æ¨¡å¼ï¼šç”¨ noisy action features æ›¿æ¢
    ...
else:
    # â­ L1 å›å½’æ¨¡å¼ï¼šæŠŠ action embedding æ¸…é›¶ï¼
    all_actions_mask = all_actions_mask.unsqueeze(-1)  # (B, seq_len, 1)
    input_embeddings = input_embeddings * ~all_actions_mask  # â† æ¸…é›¶ï¼
```

**ç»“æœ**ï¼š
- `input_ids` é‡Œçš„ GT action token ID è¿˜åœ¨ï¼ˆä½†åªç”¨äºè®¡ç®— maskï¼‰
- [input_embeddings](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:684:4-685:57) é‡Œçš„ action ä½ç½®å˜æˆäº†å…¨ 0 å‘é‡

---

### ğŸ“Œ Step 3: Loss è®¡ç®—ç”¨ GT è¿ç»­å€¼åŠ¨ä½œ

**ä½ç½®**ï¼š[vla-scripts/train.py](cci:7://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/vla-scripts/train.py:0:0-0:0) ç¬¬ 302-380 è¡Œ

```python
def run_forward_pass(...):
    # 1ï¸âƒ£ è·å– GT è¿ç»­å€¼åŠ¨ä½œï¼ˆä¸æ˜¯ tokenï¼Œæ˜¯åŸå§‹æµ®ç‚¹æ•°ï¼‰
    ground_truth_actions = batch["actions"].to(device_id)  # (B, 8, 7)
    
    # 2ï¸âƒ£ VLA å‰å‘ä¼ æ’­
    output = vla(
        input_ids=batch["input_ids"],  # å« GT action tokens
        labels=batch["labels"],         # ç”¨äºè®¡ç®— action mask
        ...
    )
    
    # 3ï¸âƒ£ è·å– action ä½ç½®çš„ hidden states
    last_hidden_states = output.hidden_states[-1]  # (B, seq_len, D)
    text_hidden_states = last_hidden_states[:, num_patches:-1]
    
    # 4ï¸âƒ£ ç”¨ mask æå– action ä½ç½®çš„ hidden states
    actions_hidden_states = text_hidden_states[current_action_mask | next_actions_mask]
    actions_hidden_states = actions_hidden_states.reshape(B, NUM_ACTIONS_CHUNK * ACTION_DIM, -1)
    
    # 5ï¸âƒ£ ç”¨ action_head é¢„æµ‹åŠ¨ä½œ
    predicted_actions = action_head.module.predict_action(actions_hidden_states)
    
    # 6ï¸âƒ£ ğŸ”¥ L1 Lossï¼šé¢„æµ‹å€¼ vs GT è¿ç»­å€¼
    loss = torch.nn.L1Loss()(ground_truth_actions, predicted_actions)
```

---

### ğŸ“Š å®Œæ•´æµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      æ•°æ®é›†æ„é€  (RLDSBatchTransform)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  input_ids: [BOS, prompt, GT_action_tokens, STOP]                   â”‚
â”‚  labels:    [-100, ..., -100, GT_action_tokens, STOP]               â”‚
â”‚  actions:   [[0.1, 0.2, ...], [...], ...] shape (8, 7) è¿ç»­å€¼       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Forward: æ¨¡å‹å†…éƒ¨å¤„ç†                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. input_embeddings = embed(input_ids)                             â”‚
â”‚     â†’ æ­¤æ—¶ action ä½ç½®æœ‰ GT embedding                               â”‚
â”‚                                                                     â”‚
â”‚  2. action_mask = _process_action_masks(labels)                     â”‚
â”‚     â†’ ç”¨ labels ä¸­çš„ GT action tokens æ‰¾åˆ° action ä½ç½®              â”‚
â”‚                                                                     â”‚
â”‚  3. input_embeddings[action_mask] = 0  â† ğŸ”¥ æ¸…é›¶ï¼                  â”‚
â”‚     â†’ action ä½ç½®å˜æˆ 0 å‘é‡                                        â”‚
â”‚                                                                     â”‚
â”‚  4. multimodal_embeddings = [BOS, patches, text(å« 0 å‘é‡)]         â”‚
â”‚     â†’ é€å…¥ LLM                                                      â”‚
â”‚                                                                     â”‚
â”‚  5. hidden_states = LLM(multimodal_embeddings)                      â”‚
â”‚     â†’ è¾“å‡º hidden states                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Loss è®¡ç®— (train.py)                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. actions_hidden = hidden_states[action_mask]                     â”‚
â”‚     â†’ æå– action ä½ç½®çš„ hidden states                              â”‚
â”‚                                                                     â”‚
â”‚  2. predicted_actions = action_head(actions_hidden)                 â”‚
â”‚     â†’ é¢„æµ‹è¿ç»­åŠ¨ä½œ                                                  â”‚
â”‚                                                                     â”‚
â”‚  3. loss = L1Loss(ground_truth_actions, predicted_actions)          â”‚
â”‚                    â†‘                      â†‘                         â”‚
â”‚            batch["actions"]   action_head çš„è¾“å‡º                    â”‚
â”‚            åŸå§‹è¿ç»­å€¼ (8,7)   é¢„æµ‹è¿ç»­å€¼ (8,7)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ğŸ”‘ å…³é”®ç‚¹æ€»ç»“

| æ•°æ® | æ¥æº | ç”¨é€” |
|------|------|------|
| `input_ids` ä¸­çš„ GT action tokens | æ•°æ®é›† tokenize | **åªç”¨äºè®¡ç®— action mask**ï¼ˆæ‰¾åˆ° action ä½ç½®ï¼‰ |
| [labels](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:807:4-817:19) | åŒ input_ids | **åŒä¸Š**ï¼Œä¸”ç”¨äºç¦»æ•£æ¨¡å¼çš„ CE loss |
| `batch["actions"]` | æ•°æ®é›†åŸå§‹è¿ç»­å€¼ | **è®¡ç®— L1 loss** |
| action ä½ç½®çš„ embedding | è¢«æ¸…é›¶ | **è®©æ¨¡å‹å­¦ä¼šä»ä¸Šä¸‹æ–‡é¢„æµ‹åŠ¨ä½œ**ï¼ˆè€Œä¸æ˜¯ç›´æ¥å¤åˆ¶ embeddingï¼‰ |

---

**ä¸‹ä¸€ä¸ªæ¨¡å—**æˆ‘ä¼šè®²è§£ **TokenPruner å‰ªæå™¨**â€”â€”LightVLA çš„æ ¸å¿ƒåˆ›æ–°ã€‚



---

## æ¨¡å— 4: TokenPruner å‰ªæå™¨ï¼ˆLightVLA æ ¸å¿ƒåˆ›æ–°ï¼‰

### ğŸ“ ä»£ç ä½ç½®
**æ–‡ä»¶**ï¼š[prismatic/extern/hf/modeling_prismatic.py](cci:7://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:0:0-0:0)  
**ç±»å®šä¹‰**ï¼šç¬¬ 49-136 è¡Œ

---

### ğŸ—ï¸ æ•´ä½“æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PrunedLlamaForCausalLM                         â”‚
â”‚  â”œâ”€â”€ PrunedLlamaModel                                       â”‚
â”‚  â”‚   â”œâ”€â”€ embed_tokens (Embedding)                           â”‚
â”‚  â”‚   â”œâ”€â”€ ğŸ”¥ pruner (TokenPruner)  â† åœ¨ Transformer å±‚ä¹‹å‰   â”‚
â”‚  â”‚   â”œâ”€â”€ layers (32 Ã— LlamaDecoderLayer)                    â”‚
â”‚  â”‚   â””â”€â”€ norm (RMSNorm)                                     â”‚
â”‚  â””â”€â”€ lm_head (Linear)                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**å…³é”®æ’å…¥ç‚¹**ï¼ˆ`PrunedLlamaModel.forward()` ç¬¬ 198 è¡Œï¼‰ï¼š

```python
# åœ¨è¿›å…¥ Transformer layers ä¹‹å‰è°ƒç”¨ pruner
hidden_states, position_ids, attention_mask = self.pruner(hidden_states, position_ids, attention_mask)
```

---

### ğŸ§© TokenPruner æ ¸å¿ƒé€»è¾‘

#### 1ï¸âƒ£ [__init__](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:554:4-570:36)ï¼šåˆå§‹åŒ–ï¼ˆç¬¬ 49-58 è¡Œï¼‰

```python
class TokenPruner(nn.Module):
    def __init__(self, config, num_patches):
        super().__init__()
        self.num_patches = num_patches           # è§†è§‰ patch æ•°é‡ï¼ˆå¦‚ 256 æˆ– 512ï¼‰
        self.noise_scale = None                  # è®­ç»ƒæ—¶çš„æ¢ç´¢å™ªå£°
        self.scale_factor = 1 / math.sqrt(config.hidden_size)  # ç¼©æ”¾å› å­
```

---

#### 2ï¸âƒ£ [forward](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:820:4-996:9)ï¼šä¸»æµç¨‹ï¼ˆç¬¬ 100-136 è¡Œï¼‰

```python
def forward(self, tokens, position_ids, attention_mask):
    bsz, seq_len, dim = tokens.shape
    
    # ğŸ”¥ Step 1: ä¸‰æ®µå¼åˆ‡åˆ†
    cls_token, patches, task = torch.split(tokens, 
        [1, self.num_patches, seq_len - self.num_patches - 1], dim=1)
    #  â””â”€ BOS    â””â”€ è§†è§‰ patches     â””â”€ æ–‡æœ¬/åŠ¨ä½œ tokens
    
    # ğŸ”¥ Step 2: è®¡ç®— patch-to-patch ç›¸ä¼¼åº¦åˆ†æ•°
    score = self.get_score(patches, task)  # (B, P, P)
    
    # ğŸ”¥ Step 3: æ ¹æ®è®­ç»ƒ/æ¨ç†æ¨¡å¼å¤„ç†
    if not self.training:  # æ¨ç†æ¨¡å¼
        # çœŸæ­£åˆ é™¤ token
        mask = self.score_to_mask(score)
        patches = patches[mask].view(bsz, -1, dim)  # åºåˆ—å˜çŸ­
    else:  # è®­ç»ƒæ¨¡å¼
        # ä¸åˆ é™¤ï¼Œåªåšè½¯èšåˆ
        indices, patches = self.score_to_indices(score, patches)  # åºåˆ—é•¿åº¦ä¸å˜
    
    # ğŸ”¥ Step 4: é‡æ–°æ‹¼æ¥
    tokens = torch.cat([cls_token, patches, task], dim=1)
    return tokens, position_ids, attention_mask
```

---

#### 3ï¸âƒ£ [get_score](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:69:4-77:20)ï¼šè®¡ç®—ç›¸ä¼¼åº¦ï¼ˆç¬¬ 70-78 è¡Œï¼‰

```python
def get_score(self, patches, prompts):
    # RMS å½’ä¸€åŒ–
    patches = self.rms_norm(patches)  # (B, P, D)
    prompts = self.rms_norm(prompts)  # (B, T, D)
    
    # ç”¨ task tokens ä½œä¸º Queryï¼Œpatches ä½œä¸ºä¸Šä¸‹æ–‡
    queries = F.scaled_dot_product_attention(patches, prompts, prompts)  # (B, P, D)
    # è§£é‡Šï¼šæ¯ä¸ª patch å»"è¯¢é—®" task tokensï¼Œå¾—åˆ° task-conditioned çš„è¡¨ç¤º
    
    queries = self.rms_norm(queries)
    
    # patch-to-patch ç›¸ä¼¼åº¦
    score = queries @ patches.transpose(-2, -1) * self.scale_factor  # (B, P, P)
    # è§£é‡Šï¼šæ¯ä¸ª patch åœ¨æ‰€æœ‰ patch ä¸­æ‰¾æœ€ç›¸ä¼¼çš„ç›®æ ‡
    
    return score
```

**å›¾è§£**ï¼š

```
patches: [P1, P2, P3, P4]  shape (B, 4, D)
task:    [T1, T2, ...]     shape (B, T, D)

Step 1: queries = attention(patches, task, task)
        â†’ æ¯ä¸ª patch æ ¹æ® task å¾—åˆ°"åº”è¯¥ä¿ç•™ä»€ä¹ˆä¿¡æ¯"çš„æŒ‡å¯¼

Step 2: score = queries @ patches.T
        â†’ score[i][j] = "patch i åº”è¯¥æŒ‡å‘ patch j çš„ç¨‹åº¦"
        â†’ å½¢çŠ¶ (B, P, P)
```

---

#### 4ï¸âƒ£ [score_to_mask](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:79:4-89:19)ï¼šæ¨ç†æ—¶ç¡¬å‰ªæï¼ˆç¬¬ 80-90 è¡Œï¼‰

```python
def score_to_mask(self, score):
    bsz = score.shape[0]
    mask = torch.zeros(bsz, self.num_patches, dtype=torch.bool, device=score.device)
    
    indices = score.argmax(-1)  # (B, P) æ¯ä¸ª patch é€‰æ‹©æŒ‡å‘å“ªä¸ªç›®æ ‡ patch
    # ä¾‹: indices = [[0, 0, 2, 0], ...]  â†’ patch 0,1,3 éƒ½æŒ‡å‘ patch 0
    
    batch_indices = torch.arange(bsz).unsqueeze(1).expand_as(indices)
    mask[batch_indices, indices] = True  # åªä¿ç•™è¢«æŒ‡å‘çš„ patch
    # ä¾‹: mask = [[True, False, True, False], ...]  â†’ åªä¿ç•™ patch 0 å’Œ 2
    
    return mask
```

**ä¾‹å­**ï¼š
```
åŸå§‹ patches: [P0, P1, P2, P3]  (4 ä¸ª)
indices:      [0, 0, 2, 0]     (P0, P1, P3 éƒ½æŒ‡å‘ P0ï¼›P2 æŒ‡å‘ P2)
unique(indices) = {0, 2}
mask:         [T, F, T, F]
ä¿ç•™å:       [P0, P2]         (åªå‰© 2 ä¸ªï¼)
```

**å…³é”®**ï¼šä¿ç•™å¤šå°‘å–å†³äº `|unique(indices)|`ï¼Œä¸æ˜¯å›ºå®šæ¯”ä¾‹ï¼

---

#### 5ï¸âƒ£ [score_to_indices](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:91:4-97:52)ï¼šè®­ç»ƒæ—¶è½¯èšåˆï¼ˆç¬¬ 92-98 è¡Œï¼‰

```python
def score_to_indices(self, score, patches):
    # å¯é€‰ï¼šæ·»åŠ æ¢ç´¢å™ªå£°
    if self.noise_scale is not None:
        score = score + torch.rand_like(score) * self.noise_scale
    
    # Straight-Through Estimator (STE)
    hard_score = F.one_hot(score.argmax(dim=-1), num_classes=self.num_patches)  # å‰å‘ç”¨ hard
    soft_score = torch.softmax(score, dim=-1)  # åå‘ç”¨ soft
    score = hard_score + soft_score - soft_score.detach()  # STE æŠ€å·§
    
    # è½¯èšåˆï¼šä¸åˆ é™¤ï¼Œè€Œæ˜¯åŠ æƒåˆå¹¶
    return score.argmax(dim=-1), score @ patches  # (B, P, D) é•¿åº¦ä¸å˜ï¼
```

**STE æŠ€å·§è§£é‡Š**ï¼š
- **å‰å‘**ï¼š`hard_score`ï¼ˆone-hotï¼‰â†’ æ¨¡æ‹ŸçœŸå®çš„ç¦»æ•£é€‰æ‹©
- **åå‘**ï¼šæ¢¯åº¦æµè¿‡ `soft_score`ï¼ˆsoftmaxï¼‰â†’ å¯å¯¼

---

### ğŸ“Š è®­ç»ƒ vs æ¨ç†å¯¹æ¯”

| é˜¶æ®µ | æ“ä½œ | åºåˆ—é•¿åº¦ | ä½œç”¨ |
|------|------|----------|------|
| **è®­ç»ƒ** | `score @ patches` è½¯èšåˆ | **ä¸å˜** (P) | å­¦ä¼š"æŠŠä¿¡æ¯èšåˆåˆ°å°‘æ•° patch" |
| **æ¨ç†** | `patches[mask]` ç¡¬å‰ªæ | **å˜çŸ­** (M â‰¤ P) | çœŸæ­£åˆ é™¤å†—ä½™ patchï¼ŒåŠ é€Ÿ |

---

### ğŸ”‘ å™ªå£°è°ƒåº¦ï¼ˆè®­ç»ƒè„šæœ¬ï¼‰

**ä½ç½®**ï¼š[train.py](cci:7://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/vla-scripts/train.py:0:0-0:0) ç¬¬ 993 è¡Œ

```python
# æ¯ä¸ª step çº¿æ€§è¡°å‡å™ªå£°
vla.module.language_model.model.pruner.set_noise_scale(1 - log_step / cfg.max_steps)
```

**ä½œç”¨**ï¼š
- è®­ç»ƒå¼€å§‹ï¼š`noise_scale=1.0`ï¼Œå¤§é‡æ¢ç´¢
- è®­ç»ƒç»“æŸï¼š`noise_scale=0`ï¼Œçº¯å­¦åˆ°çš„ç­–ç•¥

---

### ğŸ“ çœŸå®å¼ é‡å½¢çŠ¶ç¤ºä¾‹

å‡è®¾ï¼šfused + 2 å›¾ï¼Œæ¯å›¾ 256 patch â†’ `P=512`ï¼Œæ–‡æœ¬ 80 token

```
è¾“å…¥åˆ° pruner:
  tokens:      (B, 1+512+80, 4096) = (B, 593, 4096)
  position_ids: (B, 593)

å†…éƒ¨åˆ‡åˆ†:
  cls_token:   (B, 1, 4096)      â† BOS
  patches:     (B, 512, 4096)    â† è§†è§‰ patches
  task:        (B, 80, 4096)     â† æ–‡æœ¬/åŠ¨ä½œ

score è®¡ç®—:
  score:       (B, 512, 512)     â† patch-to-patch ç›¸ä¼¼åº¦

æ¨ç†æ—¶è¾“å‡º (å‡è®¾ M=120):
  tokens:      (B, 1+120+80, 4096) = (B, 201, 4096)  â† åºåˆ—å˜çŸ­ï¼
```

---

### ğŸ¯ å…³é”®ç‚¹æ€»ç»“

1. **æ’å…¥ä½ç½®**ï¼šåœ¨ Transformer layers ä¹‹å‰ï¼Œå¯¹ hidden states åšå‰ªæ
2. **ä¸‰æ®µå¼åˆ‡åˆ†**ï¼š`[BOS] + [è§†è§‰ patches] + [æ–‡æœ¬/åŠ¨ä½œ]`
3. **score å«ä¹‰**ï¼špatch-to-patchï¼Œè¡¨ç¤º"æº patch åº”è¯¥æŒ‡å‘å“ªä¸ªç›®æ ‡ patch"
4. **è®­ç»ƒä¸åŠ é€Ÿ**ï¼šç”¨è½¯èšåˆï¼Œåºåˆ—é•¿åº¦ä¸å˜
5. **æ¨ç†åŠ é€Ÿ**ï¼šç”¨ç¡¬å‰ªæï¼Œåºåˆ—çœŸæ­£å˜çŸ­
6. **ä¿ç•™å¤šå°‘éšæœº**ï¼šå–å†³äº `|unique(indices)|`ï¼Œä¸æ˜¯å›ºå®šæ¯”ä¾‹

---

**ä¸‹ä¸€ä¸ªæ¨¡å—**æˆ‘ä¼šè®²è§£ï¼š**Action Headï¼ˆåŠ¨ä½œé¢„æµ‹å¤´ï¼‰**â€”â€”L1 å›å½’å¤´å’Œ Diffusion å¤´çš„å®ç°ã€‚



### User Input

@[code_block] è¿™é‡Œæ²¡çœ‹æ‡‚
score = hard_score + soft_score - soft_score.detach() è¿™é‡Œ # å‰å‘ç”¨ hardå’Œ åå‘ç”¨ softä»€ä¹ˆæ„æ€
STE æŠ€å·§æ˜¯ä»€ä¹ˆï¼Ÿ

### Planner Response

STEï¼ˆStraight-Through Estimatorï¼‰æ˜¯æ·±åº¦å­¦ä¹ ä¸­å¤„ç†**ç¦»æ•£æ“ä½œä¸å¯å¯¼**é—®é¢˜çš„ç»å…¸æŠ€å·§ã€‚

---

## ğŸ¯ STEï¼ˆStraight-Through Estimatorï¼‰è¯¦è§£

### â“ é—®é¢˜ï¼šä¸ºä»€ä¹ˆéœ€è¦ STEï¼Ÿ

åœ¨å‰ªæä¸­ï¼Œæˆ‘ä»¬æƒ³åšçš„æ˜¯**ç¦»æ•£é€‰æ‹©**ï¼šæ¯ä¸ª patch é€‰æ‹©ä¸€ä¸ªç›®æ ‡ patchã€‚

```python
indices = score.argmax(dim=-1)  # é€‰æ‹©æœ€å¤§åˆ†æ•°çš„ index
```

ä½† `argmax` æ˜¯**ä¸å¯å¯¼**çš„ï¼æ¢¯åº¦æ— æ³•åå‘ä¼ æ’­ã€‚

```
å‰å‘: score â†’ argmax â†’ indices
åå‘: âŒ argmax çš„æ¢¯åº¦æ˜¯ 0ï¼ˆé™¤äº†æœ€å¤§å€¼ç‚¹æ˜¯ undefinedï¼‰
```

---

### ğŸ’¡ STE çš„è§£å†³æ–¹æ¡ˆ

**æ ¸å¿ƒæ€æƒ³**ï¼šå‰å‘ç”¨ç¦»æ•£æ“ä½œï¼Œåå‘"å‡è£…"ç”¨å¯å¯¼çš„æ“ä½œã€‚

```python
hard_score = F.one_hot(score.argmax(dim=-1), num_classes=P)  # ç¦»æ•£ï¼šone-hot
soft_score = torch.softmax(score, dim=-1)                    # è¿ç»­ï¼šsoftmax
score = hard_score + soft_score - soft_score.detach()        # STE æŠ€å·§
```

è®©æˆ‘é€è¡Œè§£é‡Šï¼š

---

### ğŸ“Œ Step 1: `hard_score`ï¼ˆå‰å‘ç”¨ï¼‰

```python
hard_score = F.one_hot(score.argmax(dim=-1), num_classes=P)
```

**ä¾‹å­**ï¼ˆP=4ï¼‰ï¼š
```
score = [0.1, 0.5, 0.3, 0.1]
argmax = 1
hard_score = [0, 1, 0, 0]  â† one-hot å‘é‡
```

**ä½œç”¨**ï¼šæ¨¡æ‹ŸçœŸå®çš„"ç¡¬é€‰æ‹©"â€”â€”åªé€‰ä¸€ä¸ªï¼Œå…¶ä»–å…¨ 0ã€‚

---

### ğŸ“Œ Step 2: `soft_score`ï¼ˆåå‘ç”¨ï¼‰

```python
soft_score = torch.softmax(score, dim=-1)
```

**ä¾‹å­**ï¼š
```
score = [0.1, 0.5, 0.3, 0.1]
soft_score = [0.15, 0.35, 0.25, 0.25]  â† softmax è¾“å‡º
```

**ä½œç”¨**ï¼šå¯å¯¼çš„æ¦‚ç‡åˆ†å¸ƒï¼Œæ¢¯åº¦å¯ä»¥æµè¿‡ã€‚

---

### ğŸ“Œ Step 3: STE å…¬å¼

```python
score = hard_score + soft_score - soft_score.detach()
```

**æ•°å­¦åˆ†è§£**ï¼š

```
score = hard_score + (soft_score - soft_score.detach())
      = hard_score + 0  â† å› ä¸º x - x.detach() åœ¨æ•°å€¼ä¸Š = 0
```

**ä½†æ˜¯**ï¼åœ¨æ¢¯åº¦è®¡ç®—æ—¶ï¼š

```
âˆ‚score/âˆ‚input = âˆ‚hard_score/âˆ‚input + âˆ‚soft_score/âˆ‚input - âˆ‚(soft_score.detach())/âˆ‚input
              = 0                  + âˆ‚soft_score/âˆ‚input - 0
              = âˆ‚soft_score/âˆ‚input  â† æ¢¯åº¦æ¥è‡ª softmaxï¼
```

---

### ğŸ“Š å‰å‘ vs åå‘å¯¹æ¯”

| é˜¶æ®µ | ä½¿ç”¨çš„å€¼ | æ•ˆæœ |
|------|----------|------|
| **å‰å‘** | `hard_score`ï¼ˆone-hotï¼‰ | ç¦»æ•£é€‰æ‹©ï¼Œé€‰ä¸€ä¸ª patch |
| **åå‘** | `soft_score`ï¼ˆsoftmaxï¼‰ | å¯å¯¼ï¼Œæ¢¯åº¦å¯ä»¥ä¼ æ’­ |

**å›¾è§£**ï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    å‰å‘ä¼ æ’­                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  score â†’ argmax â†’ one_hot â†’ hard_score            â”‚
â”‚                                                    â”‚
â”‚  ä½¿ç”¨ hard_score åšåç»­è®¡ç®—ï¼š                       â”‚
â”‚  patches_out = hard_score @ patches                â”‚
â”‚  = [0, 1, 0, 0] @ [P0, P1, P2, P3]                 â”‚
â”‚  = P1  â† åªé€‰äº† patch 1                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    åå‘ä¼ æ’­                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  æ¢¯åº¦ â†’ soft_score â†’ softmax â†’ score              â”‚
â”‚                                                    â”‚
â”‚  âˆ‚Loss/âˆ‚score = âˆ‚Loss/âˆ‚soft_score Ã— âˆ‚softmax/âˆ‚scoreâ”‚
â”‚                                                    â”‚
â”‚  æ¢¯åº¦å¯ä»¥æµå›å»ä¼˜åŒ– score çš„è®¡ç®—ï¼                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ğŸ¤” ç›´è§‚ç†è§£

æƒ³è±¡ä½ åœ¨æŠ•ç¥¨é€‰ç­é•¿ï¼š

- **å‰å‘ï¼ˆæŠ•ç¥¨ï¼‰**ï¼šä½ åªèƒ½æŠ•ç»™ä¸€ä¸ªäººï¼ˆç¦»æ•£é€‰æ‹©ï¼‰
- **åå‘ï¼ˆå­¦ä¹ ï¼‰**ï¼šä½†ä½ å†…å¿ƒæœ‰ä¸€ä¸ª"åå¥½åˆ†å¸ƒ"ï¼ˆè°æ›´ä¼˜ç§€çš„æ¦‚ç‡ï¼‰ï¼Œä½ æ ¹æ®è¿™ä¸ªåˆ†å¸ƒè°ƒæ•´ä½ çš„åˆ¤æ–­æ ‡å‡†

STE å°±æ˜¯ï¼š
- **å‰å‘**ï¼šæŒ‰"æœ€å¤§æ¦‚ç‡"æŠ•ç¥¨ï¼ˆone-hotï¼‰
- **åå‘**ï¼šç”¨"åå¥½åˆ†å¸ƒ"çš„æ¢¯åº¦æ¥è°ƒæ•´ä½ çš„åˆ¤æ–­æ ‡å‡†

---

### ğŸ”§ åœ¨ TokenPruner ä¸­çš„åº”ç”¨

```python
def score_to_indices(self, score, patches):
    # æ·»åŠ æ¢ç´¢å™ªå£°
    if self.noise_scale is not None:
        score = score + torch.rand_like(score) * self.noise_scale
    
    # STE
    hard_score = F.one_hot(score.argmax(dim=-1), num_classes=self.num_patches)
    soft_score = torch.softmax(score, dim=-1)
    score = hard_score + soft_score - soft_score.detach()
    
    # è½¯èšåˆ
    return score.argmax(dim=-1), score @ patches
```

**`score @ patches` çš„æ•ˆæœ**ï¼š

| é˜¶æ®µ | score å®é™…å€¼ | æ•ˆæœ |
|------|--------------|------|
| **å‰å‘** | one-hot `[0,1,0,0]` | `patches_out = P1`ï¼ˆåªé€‰ä¸€ä¸ªï¼‰ |
| **åå‘** | softmax `[0.15,0.35,0.25,0.25]` | æ¢¯åº¦æµå‘æ‰€æœ‰ patch |

**ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡ï¼Ÿ**

è®­ç»ƒæ—¶å¸Œæœ›ï¼š
1. **å‰å‘**ï¼šæ¨¡æ‹Ÿæ¨ç†æ—¶çš„ç¡¬é€‰æ‹©è¡Œä¸º
2. **åå‘**ï¼šè®©æ¨¡å‹å­¦ä¼š"æŠŠä¿¡æ¯èšåˆåˆ°å°‘æ•°é‡è¦ patch"

---

### ğŸ“š STE çš„å†å²

STE æœ€æ—©åœ¨ **Bengio et al., 2013** æå‡ºï¼Œç”¨äºè®­ç»ƒäºŒå€¼ç¥ç»ç½‘ç»œã€‚ç°åœ¨å¹¿æ³›ç”¨äºï¼š
- é‡åŒ–è®­ç»ƒ
- ç¦»æ•£ VAE
- ç¡¬æ³¨æ„åŠ›æœºåˆ¶
- **Token å‰ªæ**ï¼ˆå¦‚ LightVLAï¼‰

---

å¸Œæœ›è¿™ä¸ªè§£é‡Šå¤Ÿæ¸…æ¥šï¼ä½ è¯´"ç»§ç»­"æˆ‘å°±è®²ä¸‹ä¸€ä¸ªæ¨¡å— **Action Headï¼ˆåŠ¨ä½œé¢„æµ‹å¤´ï¼‰**~

### User Input

@[code_block] é‡æ–°ä¸¾ä¾‹æ¢³ç†ä¸€ä¸‹

### Planner Response

å¥½çš„ï¼è®©æˆ‘ç”¨ä¸€ä¸ª**å®Œæ•´çš„æ•°å€¼ä¾‹å­**æ¥é€æ­¥è®²è§£æ•´ä¸ª `TokenPruner.forward()` æµç¨‹ã€‚

---

## ğŸ¯ TokenPruner.forward() å®Œæ•´æ•°å€¼ç¤ºä¾‹

### ğŸ“‹ å‡è®¾æ¡ä»¶

```
batch_size = 1 (ç®€åŒ–)
num_patches = 4 (ç®€åŒ–ï¼Œå®é™…æ˜¯ 256 æˆ– 512)
seq_len = 1 + 4 + 3 = 8 (BOS + 4 patches + 3 task tokens)
dim = 4 (ç®€åŒ–ï¼Œå®é™…æ˜¯ 4096)
```

---

### ğŸ”¢ è¾“å…¥æ•°æ®

```python
# tokens: å½¢çŠ¶ (1, 8, 4)
tokens = [
    [BOS],      # ä½ç½® 0: BOS token
    [P0],       # ä½ç½® 1: è§†è§‰ patch 0
    [P1],       # ä½ç½® 2: è§†è§‰ patch 1
    [P2],       # ä½ç½® 3: è§†è§‰ patch 2
    [P3],       # ä½ç½® 4: è§†è§‰ patch 3
    [T0],       # ä½ç½® 5: task token 0 (æ–‡æœ¬)
    [T1],       # ä½ç½® 6: task token 1 (æ–‡æœ¬)
    [T2],       # ä½ç½® 7: task token 2 (action placeholder)
]

# å…·ä½“æ•°å€¼ (å‡è®¾ dim=4)
tokens = tensor([
    [[1, 0, 0, 0]],     # BOS
    [[0.8, 0.1, 0.0, 0.1]],  # P0 - å¤©ç©ºç‰¹å¾
    [[0.7, 0.2, 0.0, 0.1]],  # P1 - å¤©ç©ºç‰¹å¾ (å’Œ P0 ç›¸ä¼¼)
    [[0.1, 0.9, 0.0, 0.0]],  # P2 - æœºå™¨äººç‰¹å¾
    [[0.1, 0.1, 0.8, 0.0]],  # P3 - æ¡Œå­ç‰¹å¾
    [[0.0, 0.5, 0.5, 0.0]],  # T0 - "pick up"
    [[0.0, 0.6, 0.4, 0.0]],  # T1 - "the cup"
    [[0.0, 0.0, 0.0, 0.0]],  # T2 - action placeholder (æ¸…é›¶çš„)
])

position_ids = [0, 1, 2, 3, 4, 5, 6, 7]
```

---

### ğŸ”¥ Step 1: ä¸‰æ®µå¼åˆ‡åˆ†

```python
cls_token, patches, task = torch.split(tokens, [1, 4, 3], dim=1)
```

**ç»“æœ**ï¼š
```
cls_token: shape (1, 1, 4)
    [[1, 0, 0, 0]]  â† BOS

patches: shape (1, 4, 4)
    [[0.8, 0.1, 0.0, 0.1],   # P0 - å¤©ç©º
     [0.7, 0.2, 0.0, 0.1],   # P1 - å¤©ç©º
     [0.1, 0.9, 0.0, 0.0],   # P2 - æœºå™¨äºº  â† ä»»åŠ¡ç›¸å…³ï¼
     [0.1, 0.1, 0.8, 0.0]]   # P3 - æ¡Œå­    â† ä»»åŠ¡ç›¸å…³ï¼

task: shape (1, 3, 4)
    [[0.0, 0.5, 0.5, 0.0],   # "pick up"
     [0.0, 0.6, 0.4, 0.0],   # "the cup"
     [0.0, 0.0, 0.0, 0.0]]   # action placeholder
```

---

### ğŸ”¥ Step 2: è®¡ç®— `score = get_score(patches, task)`

#### 2.1 é¦–å…ˆï¼š`queries = attention(patches, task, task)`

```python
# æ¯ä¸ª patch å»"è¯¢é—®" task tokensï¼Œå¾—åˆ° task-conditioned è¡¨ç¤º
# patches ä½œä¸º Qï¼Œtask ä½œä¸º K/V

# ç®€åŒ–è®¡ç®—ï¼ˆå®é™…æ˜¯ scaled_dot_product_attentionï¼‰
# å‡è®¾ç»“æœä¸ºï¼š
queries = [
    [0.1, 0.4, 0.4, 0.1],   # P0 è¯¢é—®å â†’ å…³æ³¨"pick up"ç›¸å…³
    [0.1, 0.4, 0.4, 0.1],   # P1 è¯¢é—®å â†’ ä¹Ÿå…³æ³¨"pick up"ç›¸å…³
    [0.1, 0.7, 0.2, 0.0],   # P2 è¯¢é—®å â†’ æ›´å…³æ³¨"æœºå™¨äºº"ç»´åº¦
    [0.1, 0.5, 0.4, 0.0],   # P3 è¯¢é—®å â†’ å…³æ³¨"æ¡Œå­"ç»´åº¦
]
```

#### 2.2 ç„¶åï¼š`score = queries @ patches.T`

```
score[i][j] = queries[i] Â· patches[j]  â† è¡¨ç¤º "patch i åº”è¯¥æŒ‡å‘ patch j çš„ç¨‹åº¦"
```

**è®¡ç®—**ï¼š
```
score = queries @ patches.T

         patches.T =  P0    P1    P2    P3
                    -------------------------
queries[P0] =       [0.40, 0.35, 0.20, 0.15]  â† P0 æœ€åƒ P0
queries[P1] =       [0.40, 0.35, 0.20, 0.15]  â† P1 ä¹Ÿæœ€åƒ P0
queries[P2] =       [0.15, 0.20, 0.65, 0.15]  â† P2 æœ€åƒ P2
queries[P3] =       [0.20, 0.25, 0.45, 0.52]  â† P3 æœ€åƒ P3

score = [[0.40, 0.35, 0.20, 0.15],   # P0 æŒ‡å‘è°ï¼Ÿâ†’ P0 (æœ€å¤§)
         [0.40, 0.35, 0.20, 0.15],   # P1 æŒ‡å‘è°ï¼Ÿâ†’ P0 (æœ€å¤§)
         [0.15, 0.20, 0.65, 0.15],   # P2 æŒ‡å‘è°ï¼Ÿâ†’ P2 (æœ€å¤§)
         [0.20, 0.25, 0.45, 0.52]]   # P3 æŒ‡å‘è°ï¼Ÿâ†’ P3 (æœ€å¤§)
```

**è§£è¯»**ï¼š
- P0 å’Œ P1 éƒ½æ˜¯"å¤©ç©º"ï¼Œå®ƒä»¬éƒ½æŒ‡å‘ P0
- P2 æ˜¯"æœºå™¨äºº"ï¼Œå®ƒæŒ‡å‘è‡ªå·±
- P3 æ˜¯"æ¡Œå­"ï¼Œå®ƒæŒ‡å‘è‡ªå·±

---

### ğŸ”¥ Step 3: æ ¹æ®è®­ç»ƒ/æ¨ç†æ¨¡å¼å¤„ç†

#### 3.1 **æ¨ç†æ¨¡å¼** (`self.training = False`)

```python
mask = self.score_to_mask(score)
```

**è®¡ç®— mask**ï¼š
```
indices = score.argmax(dim=-1) = [0, 0, 2, 3]
# P0 â†’ 0, P1 â†’ 0, P2 â†’ 2, P3 â†’ 3

mask = [True, False, True, True]
# P0 è¢«æŒ‡å‘ (è¢« P0, P1 æŒ‡å‘)
# P1 æ²¡è¢«æŒ‡å‘ (å®ƒæŒ‡å‘äº† P0)
# P2 è¢«æŒ‡å‘ (è‡ªå·±æŒ‡å‘è‡ªå·±)
# P3 è¢«æŒ‡å‘ (è‡ªå·±æŒ‡å‘è‡ªå·±)
```

**åº”ç”¨ mask**ï¼š
```python
patches = patches[mask].view(bsz, -1, dim)
# åªä¿ç•™ P0, P2, P3
# patches ä» (1, 4, 4) å˜æˆ (1, 3, 4)

patches = [
    [0.8, 0.1, 0.0, 0.1],   # P0 - å¤©ç©º (ä»£è¡¨ P0 å’Œ P1)
    [0.1, 0.9, 0.0, 0.0],   # P2 - æœºå™¨äºº
    [0.1, 0.1, 0.8, 0.0],   # P3 - æ¡Œå­
]
# P1 è¢«åˆ é™¤äº†ï¼å› ä¸ºå®ƒå’Œ P0 å¤ªåƒ
```

**æ¨ç†æ•ˆæœ**ï¼š
```
åŸåºåˆ—: [BOS, P0, P1, P2, P3, T0, T1, T2]  é•¿åº¦ = 8
æ–°åºåˆ—: [BOS, P0, P2, P3, T0, T1, T2]      é•¿åº¦ = 7  â† å˜çŸ­äº†ï¼
```

---

#### 3.2 **è®­ç»ƒæ¨¡å¼** (`self.training = True`)

```python
indices, patches = self.score_to_indices(score, patches)
```

**Step 3.2.1: æ·»åŠ å™ªå£°ï¼ˆå¦‚æœæœ‰ï¼‰**
```python
if self.noise_scale is not None:
    score = score + torch.rand_like(score) * self.noise_scale
```

**Step 3.2.2: STE å¤„ç†**
```python
hard_score = F.one_hot(score.argmax(dim=-1), num_classes=4)
# hard_score = [[1,0,0,0],  # P0 æŒ‡å‘ P0
#               [1,0,0,0],  # P1 æŒ‡å‘ P0
#               [0,0,1,0],  # P2 æŒ‡å‘ P2
#               [0,0,0,1]]  # P3 æŒ‡å‘ P3

soft_score = torch.softmax(score, dim=-1)
# soft_score â‰ˆ [[0.35, 0.30, 0.20, 0.15],
#               [0.35, 0.30, 0.20, 0.15],
#               [0.15, 0.20, 0.50, 0.15],
#               [0.15, 0.20, 0.30, 0.35]]

score = hard_score + soft_score - soft_score.detach()
# æ•°å€¼ä¸Š = hard_score (one-hot)
# æ¢¯åº¦ä¸Šèµ° soft_score
```

**Step 3.2.3: è½¯èšåˆ**
```python
patches = score @ patches
# ç”¨ one-hot çŸ©é˜µåšçŸ©é˜µä¹˜æ³•

patches = [[1,0,0,0],     @ [[P0],     = [[P0],   # åŸ P0 å˜æˆ P0
           [1,0,0,0],        [P1],        [P0],   # åŸ P1 ä¹Ÿå˜æˆ P0ï¼
           [0,0,1,0],        [P2],        [P2],   # åŸ P2 è¿˜æ˜¯ P2
           [0,0,0,1]]        [P3]]        [P3]]   # åŸ P3 è¿˜æ˜¯ P3
```

**è®­ç»ƒæ•ˆæœ**ï¼š
```
åŸåºåˆ—: [BOS, P0, P1, P2, P3, T0, T1, T2]  é•¿åº¦ = 8
æ–°åºåˆ—: [BOS, P0, P0, P2, P3, T0, T1, T2]  é•¿åº¦ = 8  â† é•¿åº¦ä¸å˜ï¼
                  â†‘
              P1 çš„å†…å®¹è¢«æ›¿æ¢æˆäº† P0
```

---

### ğŸ”¥ Step 4: é‡æ–°æ‹¼æ¥

```python
tokens = torch.cat([cls_token, patches, task], dim=1)
```

#### æ¨ç†æ—¶ï¼š
```
tokens = [BOS, P0, P2, P3, T0, T1, T2]
é•¿åº¦ä» 8 å˜æˆ 7ï¼ŒçœŸæ­£åŠ é€Ÿï¼
```

#### è®­ç»ƒæ—¶ï¼š
```
tokens = [BOS, P0, P0, P2, P3, T0, T1, T2]
é•¿åº¦è¿˜æ˜¯ 8ï¼Œä½† P1 ä½ç½®çš„å†…å®¹å˜æˆäº† P0
```

---

### ğŸ“Š å®Œæ•´å¯¹æ¯”

| é˜¶æ®µ | è¾“å…¥é•¿åº¦ | è¾“å‡ºé•¿åº¦ | P1 å‘ç”Ÿäº†ä»€ä¹ˆ |
|------|----------|----------|---------------|
| **æ¨ç†** | 8 | 7 | **è¢«åˆ é™¤**ï¼ˆç‰©ç†åˆ é™¤ï¼‰ |
| **è®­ç»ƒ** | 8 | 8 | **è¢«æ›¿æ¢æˆ P0**ï¼ˆè½¯èšåˆï¼‰ |

---

### ğŸ¯ ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡ï¼Ÿ

**è®­ç»ƒæ—¶**ï¼š
- è®©æ¨¡å‹å­¦ä¼š"P0 å’Œ P1 æ˜¯ç›¸ä¼¼çš„ï¼Œå¯ä»¥åˆå¹¶"
- æ¢¯åº¦å¯ä»¥é€šè¿‡ softmax åä¼ ï¼Œä¼˜åŒ– score çš„è®¡ç®—

**æ¨ç†æ—¶**ï¼š
- çœŸæ­£åˆ é™¤å†—ä½™ tokenï¼Œå‡å°‘ Transformer çš„è®¡ç®—é‡
- å› ä¸ºè®­ç»ƒæ—¶å·²ç»å­¦ä¼šäº†"P0 å¯ä»¥ä»£è¡¨ P1"ï¼Œæ‰€ä»¥åˆ é™¤ P1 ä¸ä¼šä¸¢å¤±é‡è¦ä¿¡æ¯

---

å¸Œæœ›è¿™ä¸ªä¾‹å­å¤Ÿæ¸…æ¥šï¼Œä¸‹ä¸€ä¸ªæ¨¡å— **Action Headï¼ˆåŠ¨ä½œé¢„æµ‹å¤´ï¼‰**~

æ›´ç›´è§‚çš„æ–¹å¼è§£é‡Š `score[i][j]` çš„å«ä¹‰ã€‚

---

## ğŸ¯ `score[i][j]` è¯¦è§£ï¼špatch ä¹‹é—´çš„"æŠ•ç¥¨/æŒ‡å‘"å…³ç³»

### â“ é—®é¢˜ï¼š`score[i][j]` åˆ°åº•è¡¨ç¤ºä»€ä¹ˆï¼Ÿ

**é€šä¿—è§£é‡Š**ï¼š

```
score[i][j] = "patch i è§‰å¾— patch j æœ‰å¤šé‡è¦ï¼Œæ˜¯å¦å¯ä»¥ä»£è¡¨è‡ªå·±"
```

å¦‚æœ `score[i][j]` å¾ˆå¤§ï¼Œè¯´æ˜ï¼š
- patch i è®¤ä¸º patch j å’Œè‡ªå·±å¾ˆç›¸ä¼¼
- æˆ–è€… patch j åŒ…å«äº† patch i æƒ³è¡¨è¾¾çš„ä¿¡æ¯
- **ç»“è®º**ï¼špatch i å¯ä»¥è¢« patch j "ä»£è¡¨"ï¼Œæ‰€ä»¥ patch i å¯ä»¥è¢«åˆ æ‰

---

### ğŸ“Š ç”¨å…·ä½“åœºæ™¯ç†è§£

å‡è®¾ä¸€å¼ å›¾ç‰‡æœ‰ 4 ä¸ª patchï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  P0     â”‚  P1     â”‚
â”‚  å¤©ç©º   â”‚  å¤©ç©º    â”‚  â† P0 å’Œ P1 éƒ½æ˜¯å¤©ç©ºï¼Œå¾ˆç›¸ä¼¼
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  P2     â”‚  P3     â”‚
â”‚ æœºå™¨äºº  â”‚  æ¯å­    â”‚  â† P2 æ˜¯æœºå™¨äººï¼ŒP3 æ˜¯æ¯å­
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

ä»»åŠ¡æ˜¯ï¼š"pick up the cup"ï¼ˆæ‹¿èµ·æ¯å­ï¼‰

---

### ğŸ”¢ score çŸ©é˜µçš„å«ä¹‰

```
           è¢«æŠ•ç¥¨è€…ï¼ˆç›®æ ‡ patchï¼‰
           P0    P1    P2    P3
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
æŠ•ç¥¨è€… P0â”‚ 0.4  0.35  0.2  0.15â”‚  â† P0 æœ€æŠ•ç»™ P0ï¼ˆè‡ªå·±ï¼‰æˆ– P1ï¼ˆä¹Ÿæ˜¯å¤©ç©ºï¼‰
(æº patch)â”‚                     â”‚
       P1â”‚ 0.4  0.35  0.2  0.15â”‚  â† P1 ä¹Ÿæ˜¯å¤©ç©ºï¼Œæœ€æŠ•ç»™ P0
         â”‚                     â”‚
       P2â”‚ 0.15 0.2   0.5  0.15â”‚  â† P2 æ˜¯æœºå™¨äººï¼Œæœ€æŠ•ç»™è‡ªå·±
         â”‚                     â”‚
       P3â”‚ 0.15 0.2   0.15 0.5 â”‚  â† P3 æ˜¯æ¯å­ï¼Œæœ€æŠ•ç»™è‡ªå·±
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**è§£è¯»**ï¼š
- `score[0][0] = 0.4`ï¼šP0 è§‰å¾— P0ï¼ˆè‡ªå·±ï¼‰å¯ä»¥ä»£è¡¨è‡ªå·±
- `score[1][0] = 0.4`ï¼šP1 è§‰å¾— P0 å¯ä»¥ä»£è¡¨è‡ªå·± â† **å…³é”®ï¼P1 æ„¿æ„è¢« P0 ä»£è¡¨**
- `score[2][2] = 0.5`ï¼šP2 è§‰å¾—åªæœ‰è‡ªå·±èƒ½ä»£è¡¨è‡ªå·±ï¼ˆæœºå™¨äººæ˜¯ç‹¬ç‰¹çš„ï¼‰
- `score[3][3] = 0.5`ï¼šP3 è§‰å¾—åªæœ‰è‡ªå·±èƒ½ä»£è¡¨è‡ªå·±ï¼ˆæ¯å­æ˜¯ç‹¬ç‰¹çš„ï¼‰

---

### ğŸ—³ï¸ æŠ•ç¥¨è¿‡ç¨‹

```python
indices = score.argmax(dim=-1)  # æ¯è¡Œé€‰æœ€å¤§çš„é‚£ä¸ª
```

```
P0 æŠ•ç»™è°ï¼Ÿ argmax([0.4, 0.35, 0.2, 0.15]) = 0 â†’ æŠ•ç»™ P0
P1 æŠ•ç»™è°ï¼Ÿ argmax([0.4, 0.35, 0.2, 0.15]) = 0 â†’ æŠ•ç»™ P0
P2 æŠ•ç»™è°ï¼Ÿ argmax([0.15, 0.2, 0.5, 0.15]) = 2 â†’ æŠ•ç»™ P2
P3 æŠ•ç»™è°ï¼Ÿ argmax([0.15, 0.2, 0.15, 0.5]) = 3 â†’ æŠ•ç»™ P3

indices = [0, 0, 2, 3]
```

**å›¾ç¤º**ï¼š
```
P0 â”€â”€â†’ P0 â†â”€â”€ P1    (P0 å’Œ P1 éƒ½æŠ•ç»™ P0)
       â†“
      è¢«ä¿ç•™

P2 â”€â”€â†’ P2           (P2 æŠ•ç»™è‡ªå·±)
       â†“
      è¢«ä¿ç•™

P3 â”€â”€â†’ P3           (P3 æŠ•ç»™è‡ªå·±)
       â†“
      è¢«ä¿ç•™
```

---

### ğŸ¯ æœ€ç»ˆæ•ˆæœ

**æ¨ç†æ—¶**ï¼š
```
è¢«æŠ•ç¥¨çš„ patches = unique(indices) = {0, 2, 3}
P1 æ²¡äººæŠ•ç¥¨ç»™å®ƒï¼ˆå®ƒæŠ•ç»™äº†åˆ«äººï¼‰â†’ è¢«åˆ é™¤ï¼

åŸå§‹: [P0, P1, P2, P3]
ä¿ç•™: [P0, P2, P3]  â† P1 è¢«åˆ é™¤äº†
```

**ä¸ºä»€ä¹ˆ P1 å¯ä»¥åˆ ï¼Ÿ**

å› ä¸º P1 è‡ªå·±éƒ½è§‰å¾— "P0 å¯ä»¥ä»£è¡¨æˆ‘"ï¼ˆ`score[1][0] = 0.4` æ˜¯ P1 é‚£è¡Œçš„æœ€å¤§å€¼ï¼‰ï¼Œæ‰€ä»¥åˆ æ‰ P1 ä¸ä¼šä¸¢å¤±ä¿¡æ¯â€”â€”P0 å·²ç»åŒ…å«äº† P1 æƒ³è¡¨è¾¾çš„å†…å®¹ã€‚

---

### ğŸ“Œ æ€»ç»“

| `score[i][j]` | å«ä¹‰ |
|---------------|------|
| é«˜åˆ† | patch i è§‰å¾— patch j å¯ä»¥ä»£è¡¨è‡ªå·± |
| ä½åˆ† | patch i è§‰å¾— patch j ä¸èƒ½ä»£è¡¨è‡ªå·± |
| `argmax` | patch i é€‰æ‹©"æœ€èƒ½ä»£è¡¨è‡ªå·±"çš„ patch j |
| è¢«é€‰ä¸­çš„ | ä¿ç•™ |
| æ²¡è¢«é€‰ä¸­çš„ | åˆ é™¤ï¼ˆå†—ä½™ï¼‰ |

**æ ¸å¿ƒæ€æƒ³**ï¼šå¦‚æœå¾ˆå¤š patch éƒ½æŒ‡å‘åŒä¸€ä¸ª patchï¼Œè¯´æ˜é‚£ä¸ª patch æ˜¯"ä¿¡æ¯ä¸­å¿ƒ"ï¼Œå…¶ä»–æŒ‡å‘å®ƒçš„ patch éƒ½æ˜¯å†—ä½™çš„ï¼Œå¯ä»¥åˆ æ‰ã€‚

---

ä¸‹ä¸€ä¸ªæ¨¡å— **Action Headï¼ˆåŠ¨ä½œé¢„æµ‹å¤´ï¼‰**~





---

## æ¨¡å— 5: Action Headï¼ˆåŠ¨ä½œé¢„æµ‹å¤´ï¼‰

### ğŸ“ ä»£ç ä½ç½®
**æ–‡ä»¶**ï¼š[prismatic/models/action_heads.py](cci:7://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/models/action_heads.py:0:0-0:0)

LightVLA æ”¯æŒä¸¤ç§åŠ¨ä½œé¢„æµ‹æ–¹å¼ï¼š
1. **L1 å›å½’å¤´**ï¼ˆé»˜è®¤ï¼‰ï¼šç›´æ¥é¢„æµ‹è¿ç»­åŠ¨ä½œ
2. **Diffusion å¤´**ï¼šé€šè¿‡å»å™ªç”ŸæˆåŠ¨ä½œ

---

### ğŸ—ï¸ æ•´ä½“æ¶æ„

```
VLA æ¨¡å‹ Forward è¾“å‡º
        â”‚
        â–¼
hidden_states[:, action_positions, :]  æå– action ä½ç½®çš„ç‰¹å¾
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Action Head                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  L1RegressionActionHead         â”‚  â”‚  â† é»˜è®¤
â”‚  â”‚  æˆ–                              â”‚  â”‚
â”‚  â”‚  DiffusionActionHead            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â–¼
predicted_actions: (B, NUM_ACTIONS_CHUNK, ACTION_DIM)
ä¾‹å¦‚ LIBERO: (B, 8, 7)
```

---

### 1ï¸âƒ£ [L1RegressionActionHead](cci:2://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/models/action_heads.py:83:0-106:21)ï¼ˆé»˜è®¤ï¼Œç¬¬ 84-107 è¡Œï¼‰

**æœ€ç®€å•æœ€ç›´æ¥çš„æ–¹å¼**ï¼šç”¨ MLP ç›´æ¥é¢„æµ‹è¿ç»­åŠ¨ä½œã€‚

```python
class L1RegressionActionHead(nn.Module):
    def __init__(self, input_dim=4096, hidden_dim=4096, action_dim=7):
        super().__init__()
        self.action_dim = action_dim
        self.model = MLPResNet(
            num_blocks=2,
            input_dim=input_dim * ACTION_DIM,  # ä¾‹: 4096 * 7 = 28672
            hidden_dim=hidden_dim,              # 4096
            output_dim=action_dim               # 7
        )
    
    def predict_action(self, actions_hidden_states):
        # è¾“å…¥: (B, chunk_len * action_dim, hidden_dim)
        #       ä¾‹: (B, 8*7=56, 4096)
        batch_size = actions_hidden_states.shape[0]
        
        # é‡æ’: (B, chunk_len, action_dim * hidden_dim)
        #       ä¾‹: (B, 8, 7*4096=28672)
        rearranged = actions_hidden_states.reshape(batch_size, NUM_ACTIONS_CHUNK, -1)
        
        # MLP é¢„æµ‹: (B, chunk_len, action_dim)
        #           ä¾‹: (B, 8, 7)
        action = self.model(rearranged)
        return action
```

**æ•°æ®æµ**ï¼š
```
actions_hidden_states: (B, 56, 4096)
            â”‚
            â–¼ reshape
        (B, 8, 28672)  â† æ¯ä¸ªæ—¶é—´æ­¥çš„ç‰¹å¾
            â”‚
            â–¼ MLPResNet (å¯¹æ¯ä¸ªæ—¶é—´æ­¥ç‹¬ç«‹å¤„ç†)
        (B, 8, 7)  â† é¢„æµ‹çš„åŠ¨ä½œ
```

**MLPResNet ç»“æ„**ï¼ˆç¬¬ 59-81 è¡Œï¼‰ï¼š
```
LayerNorm â†’ Linear(28672â†’4096) â†’ ReLU
    â†’ [ResBlock Ã— 2]
    â†’ LayerNorm â†’ Linear(4096â†’7)

å…¶ä¸­ ResBlock:
    LayerNorm â†’ Linear â†’ ReLU + æ®‹å·®è¿æ¥
```

---

### 2ï¸âƒ£ [DiffusionActionHead](cci:2://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/models/action_heads.py:143:0-210:25)ï¼ˆç¬¬ 144-211 è¡Œï¼‰

**æ›´å¤æ‚ä½†æ›´å¼ºå¤§**ï¼šé€šè¿‡æ‰©æ•£æ¨¡å‹ç”ŸæˆåŠ¨ä½œã€‚

#### æ ¸å¿ƒç»„ä»¶ï¼š

```python
class DiffusionActionHead(nn.Module):
    def __init__(self, input_dim=4096, hidden_dim=4096, action_dim=7, 
                 num_diffusion_steps_train=50):
        super().__init__()
        
        # å™ªå£°é¢„æµ‹ç½‘ç»œ
        self.noise_predictor = NoisePredictionModel(
            transformer_hidden_dim=hidden_dim * ACTION_DIM,  # 28672
            hidden_dim=hidden_dim,                            # 4096
            action_dim=action_dim                             # 7
        )
        
        # æ‰©æ•£è°ƒåº¦å™¨ (DDIM)
        self.noise_scheduler = DDIMScheduler(
            num_train_timesteps=num_diffusion_steps_train,    # 50
            beta_schedule="squaredcos_cap_v2"
        )
        
        # æ—¶é—´æ­¥ç¼–ç å™¨
        self.time_encoder = SinusoidalPositionalEncoding(dim=hidden_dim)
```

#### è®­ç»ƒæ—¶ï¼š[sample_noisy_actions()](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/models/action_heads.py:166:4-196:26)ï¼ˆç¬¬ 167-197 è¡Œï¼‰

```python
def sample_noisy_actions(self, ground_truth_actions):
    batch_size = ground_truth_actions.shape[0]
    
    # 1ï¸âƒ£ é‡‡æ ·éšæœºå™ªå£°
    noise = torch.randn(size=(batch_size, NUM_ACTIONS_CHUNK, ACTION_DIM))
    
    # 2ï¸âƒ£ é‡‡æ ·éšæœºæ—¶é—´æ­¥
    timesteps = torch.randint(low=0, high=50, size=(batch_size,))
    
    # 3ï¸âƒ£ ç»™ GT åŠ¨ä½œåŠ å™ªå£°
    noisy_actions = noise_scheduler.add_noise(ground_truth_actions, noise, timesteps)
    
    # 4ï¸âƒ£ ç¼–ç æ—¶é—´æ­¥
    diffusion_timestep_embeddings = self.time_encoder(timesteps)
    
    return {
        "noise": noise,                              # ç”¨äºè®¡ç®— loss
        "noisy_actions": noisy_actions,              # é€å…¥æ¨¡å‹
        "diffusion_timestep_embeddings": embeddings  # æ—¶é—´æ­¥ä¿¡æ¯
    }
```

**å›¾è§£**ï¼š
```
GT åŠ¨ä½œ: [0.1, 0.2, 0.3, ...]      å™ªå£°: [0.5, -0.3, 0.1, ...]
            â”‚                           â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â–¼
                    åŠ å™ª (æŒ‰ timestep)
                          â–¼
        noisy_actions: [0.35, 0.05, 0.25, ...]
```

#### æ¨ç†æ—¶ï¼šå¤šæ­¥å»å™ª

```
Step 1: çº¯å™ªå£° â†’ æ¨¡å‹é¢„æµ‹å™ªå£° â†’ å»å™ªå¾—åˆ° x_{t-1}
Step 2: x_{t-1} â†’ æ¨¡å‹é¢„æµ‹å™ªå£° â†’ å»å™ªå¾—åˆ° x_{t-2}
...
Step 50: x_1 â†’ æ¨¡å‹é¢„æµ‹å™ªå£° â†’ å»å™ªå¾—åˆ° x_0 (å¹²å‡€åŠ¨ä½œ)
```

---

### ğŸ“Š L1 å›å½’ vs Diffusion å¯¹æ¯”

| ç‰¹æ€§ | L1 å›å½’å¤´ | Diffusion å¤´ |
|------|-----------|--------------|
| **è®­ç»ƒ** | 1 æ¬¡å‰å‘ | 1 æ¬¡å‰å‘ |
| **æ¨ç†** | 1 æ¬¡å‰å‘ | **50 æ¬¡å‰å‘** |
| **å¤æ‚åº¦** | ç®€å• | å¤æ‚ |
| **è¡¨è¾¾èƒ½åŠ›** | å•å³°åˆ†å¸ƒ | å¤šå³°åˆ†å¸ƒ |
| **é€Ÿåº¦** | å¿« | æ…¢ |
| **é»˜è®¤** | âœ… æ˜¯ | âŒ å¦ |

---

### ğŸ”§ åœ¨è®­ç»ƒè„šæœ¬ä¸­çš„ä½¿ç”¨

**ä½ç½®**ï¼š[train.py](cci:7://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/vla-scripts/train.py:0:0-0:0) ç¬¬ 841-868 è¡Œ

```python
# åˆå§‹åŒ– Action Head
if cfg.use_l1_regression:  # é»˜è®¤
    action_head = init_module(
        L1RegressionActionHead,
        "action_head",
        cfg,
        device_id,
        {"input_dim": vla.module.llm_dim, "hidden_dim": vla.module.llm_dim, "action_dim": ACTION_DIM},
    )

if cfg.use_diffusion:
    action_head = init_module(
        DiffusionActionHead,
        "action_head",
        cfg,
        device_id,
        {
            "input_dim": vla.module.llm_dim,
            "hidden_dim": vla.module.llm_dim,
            "action_dim": ACTION_DIM,
            "num_diffusion_steps_train": cfg.num_diffusion_steps_train,
        },
    )
```

---

### ğŸ¯ å…³é”®ç‚¹æ€»ç»“

1. **L1 å›å½’**ï¼ˆé»˜è®¤ï¼‰ï¼šç®€å•é«˜æ•ˆï¼Œç›´æ¥é¢„æµ‹åŠ¨ä½œ
2. **Diffusion**ï¼šè¡¨è¾¾èƒ½åŠ›å¼ºï¼Œä½†æ¨ç†æ…¢ 50 å€
3. **è¾“å…¥**ï¼šä» LLM hidden states ä¸­æå– action ä½ç½®çš„ç‰¹å¾
4. **è¾“å‡º**ï¼š[(B, NUM_ACTIONS_CHUNK, ACTION_DIM)](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/vla/datasets/rlds/dataset.py:413:8-416:53) çš„è¿ç»­åŠ¨ä½œ
5. **Loss**ï¼šL1 ç”¨ L1Lossï¼ŒDiffusion ç”¨ MSELossï¼ˆå™ªå£°é¢„æµ‹ï¼‰

---

**ä¸‹ä¸€ä¸ªæ¨¡å—**æˆ‘ä¼šè®²è§£ï¼š**æ¨ç†æµç¨‹ï¼ˆpredict_actionï¼‰**â€”â€”æ¨¡å‹å¦‚ä½•åœ¨çœŸå®æœºå™¨äººä¸Šè¿è¡Œã€‚



---

## æ¨¡å— 6: æ¨ç†æµç¨‹ï¼ˆpredict_actionï¼‰

### ğŸ“ ä»£ç ä½ç½®
**æ–‡ä»¶**ï¼š[prismatic/extern/hf/modeling_prismatic.py](cci:7://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:0:0-0:0)  
**å‡½æ•°**ï¼š`OpenVLAForActionPrediction.predict_action()`ï¼ˆç¬¬ 1271-1376 è¡Œï¼‰

è¿™æ˜¯**æ¨¡å‹éƒ¨ç½²åˆ°çœŸå®æœºå™¨äºº**æ—¶è°ƒç”¨çš„ä¸»å‡½æ•°ã€‚

---

### ğŸ”„ å®Œæ•´æ¨ç†æµç¨‹å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    è¾“å…¥ï¼ˆæ¥è‡ªæœºå™¨äººï¼‰                        â”‚
â”‚  - å›¾åƒ: pixel_values (1, C, H, W)                          â”‚
â”‚  - æŒ‡ä»¤: input_ids (1, S) - "pick up the cup"               â”‚
â”‚  - [å¯é€‰] proprio: å½“å‰å…³èŠ‚çŠ¶æ€                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 1: å‡†å¤‡è¾“å…¥åºåˆ—ï¼ˆç¬¬ 1314-1318 è¡Œï¼‰                     â”‚
â”‚  _prepare_input_for_action_prediction()                     â”‚
â”‚  â†’ æ·»åŠ  56 ä¸ª action å ä½ç¬¦ + STOP token                    â”‚
â”‚  input_ids: [BOS, prompt, placeholderÃ—56, STOP]             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 2: è·å– embeddings å¹¶æ¸…é›¶ action ä½ç½®ï¼ˆç¬¬ 1321-1322ï¼‰  â”‚
â”‚  input_embeddings = embed(input_ids)                        â”‚
â”‚  input_embeddings[action_mask] = 0                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 3: å¤„ç†è§†è§‰ç‰¹å¾ï¼ˆç¬¬ 1330 è¡Œï¼‰                          â”‚
â”‚  projected_patch_embeddings = _process_vision_features()    â”‚
â”‚  â†’ å¦‚æœç”¨ proprio: è¿½åŠ  proprio token                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 4: é€‰æ‹©é¢„æµ‹æ–¹å¼ï¼ˆç¬¬ 1341-1371 è¡Œï¼‰                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚  â”‚ use_diffusion?    â”‚  â”‚ action_head?      â”‚              â”‚
â”‚  â”‚  â†’ Diffusion æ¨ç†  â”‚  â”‚  â†’ L1 å›å½’æ¨ç†     â”‚              â”‚
â”‚  â”‚  (50 æ­¥å»å™ª)       â”‚  â”‚  (1 æ­¥å‰å‘)        â”‚              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚                         â”‚ éƒ½æ²¡æœ‰?           â”‚              â”‚
â”‚                         â”‚  â†’ ç¦»æ•£ token é¢„æµ‹ â”‚              â”‚
â”‚                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Step 5: åŠ¨ä½œåå½’ä¸€åŒ–ï¼ˆç¬¬ 1374 è¡Œï¼‰                          â”‚
â”‚  actions = _unnormalize_actions(normalized_actions)         â”‚
â”‚  â†’ ä» [-1, 1] æ˜ å°„å›çœŸå®æœºå™¨äººåŠ¨ä½œç©ºé—´                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    è¾“å‡ºï¼ˆå‘é€ç»™æœºå™¨äººï¼‰                      â”‚
â”‚  actions: (8, 7) numpy array                                â”‚
â”‚  ä¾‹: [[Î”x, Î”y, Î”z, Î”rx, Î”ry, Î”rz, gripper], ...]           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### ğŸ“Œ å…³é”®æ­¥éª¤è¯¦è§£

#### Step 1: å‡†å¤‡è¾“å…¥åºåˆ—ï¼ˆç¬¬ 1314-1315 è¡Œï¼‰

```python
input_ids, attention_mask = self._prepare_input_for_action_prediction(input_ids, attention_mask)
```

**ä½œç”¨**ï¼šæ¨ç†æ—¶æ²¡æœ‰ GT action tokensï¼Œéœ€è¦æ·»åŠ å ä½ç¬¦ã€‚

```
åŸå§‹: [BOS, "What action...", "pick up the cup?"]
æ·»åŠ å: [BOS, "What action...", placeholderÃ—56, STOP]
         â†‘ prompt                â†‘ action ä½ç½®     â†‘ ç»“æŸ
```

---

#### Step 2: æ¸…é›¶ action embeddingï¼ˆç¬¬ 1321-1322 è¡Œï¼‰

```python
input_embeddings = self.get_input_embeddings()(input_ids)
all_actions_mask = self._process_action_masks(labels)
```

ç„¶ååœ¨ [_regression_or_discrete_prediction()](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:1204:4-1268:56) ä¸­ï¼ˆç¬¬ 1217-1218 è¡Œï¼‰ï¼š
```python
all_actions_mask = all_actions_mask.unsqueeze(-1)
input_embeddings = input_embeddings * ~all_actions_mask  # æ¸…é›¶
```

---

#### Step 3: å¤„ç†è§†è§‰ç‰¹å¾ï¼ˆç¬¬ 1330-1338 è¡Œï¼‰

```python
# æå–è§†è§‰ç‰¹å¾
projected_patch_embeddings = self._process_vision_features(pixel_values, language_embeddings, use_film)

# å¦‚æœç”¨ proprioï¼Œè¿½åŠ åˆ° patch åºåˆ—åé¢
if use_proprio:
    projected_patch_embeddings = self._process_proprio_features(
        projected_patch_embeddings, proprio, proprio_projector
    )
```

---

#### Step 4: ä¸‰ç§é¢„æµ‹æ–¹å¼

**4.1 Diffusion æ¨ç†**ï¼ˆç¬¬ 1343-1360 è¡Œï¼‰ï¼š
```python
if use_diffusion:
    noise = torch.randn(size=(1, 8, 7))  # éšæœºå™ªå£°èµ·ç‚¹
    normalized_actions = self._run_diffusion_prediction(...)  # 50 æ­¥å»å™ª
```

**4.2 L1 å›å½’æ¨ç†**ï¼ˆç¬¬ 1248-1252 è¡Œï¼‰ï¼š
```python
if action_head is not None:
    normalized_actions = action_head.predict_action(actions_hidden_states)
```

**4.3 ç¦»æ•£ token é¢„æµ‹**ï¼ˆç¬¬ 1254-1267 è¡Œï¼‰ï¼š
```python
else:
    # ç”¨ logits çš„ argmax é¢„æµ‹ token ID
    predicted_action_token_ids = language_model_output.logits[...].argmax(dim=2)
    # æŠŠ token ID è½¬å›è¿ç»­å€¼
    normalized_actions = self.bin_centers[discretized_actions]
```

---

#### Step 5: åŠ¨ä½œåå½’ä¸€åŒ–ï¼ˆç¬¬ 1373-1374 è¡Œï¼‰

```python
actions = self._unnormalize_actions(normalized_actions, unnorm_key)
```

**è®¡ç®—**ï¼ˆç¬¬ 1114-1118 è¡Œï¼‰ï¼š
```python
# ä» [-1, 1] æ˜ å°„å›çœŸå®åŠ¨ä½œç©ºé—´
actions = 0.5 * (normalized_actions + 1) * (action_high - action_low) + action_low
```

**ä¾‹å­**ï¼š
```
normalized: 0.5 (åœ¨ [-1, 1] èŒƒå›´å†…)
action_low = -0.1, action_high = 0.1
real_action = 0.5 * (0.5 + 1) * (0.1 - (-0.1)) + (-0.1)
            = 0.5 * 1.5 * 0.2 - 0.1
            = 0.05
```

---

### âš¡ LightVLA çš„æ¨ç†åŠ é€Ÿ

**å…³é”®**ï¼šæ¨ç†æ—¶ [TokenPruner](cci:2://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:48:0-135:51) ä¼šçœŸæ­£åˆ é™¤ patch tokenï¼

```
åŸå§‹åºåˆ—: [BOS] + [512 patches] + [80 text/action]  = 593 tokens
å‰ªæå:   [BOS] + [~150 patches] + [80 text/action] = 231 tokens

Transformer self-attention å¤æ‚åº¦: O(nÂ²)
åŠ é€Ÿæ¯”: (593/231)Â² â‰ˆ 6.6x
```

---

### ğŸ“Š æ¨ç†æ—¶é—´å¯¹æ¯”ï¼ˆç¤ºæ„ï¼‰

| æ–¹æ³• | åºåˆ—é•¿åº¦ | å‰å‘æ¬¡æ•° | ç›¸å¯¹æ—¶é—´ |
|------|----------|----------|----------|
| OpenVLA-OFT (ç¦»æ•£) | 593 | 1 | 1.0x |
| LightVLA (L1 å›å½’) | ~231 | 1 | **~0.15x** |
| LightVLA (Diffusion) | ~231 | 50 | ~7.5x |

---

### ğŸ¯ å…³é”®ç‚¹æ€»ç»“

1. **å…¥å£å‡½æ•°**ï¼š[predict_action()](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/models/action_heads.py:97:4-106:21) æ˜¯æœºå™¨äººè°ƒç”¨çš„ä¸»æ¥å£
2. **è¾“å…¥å‡†å¤‡**ï¼šæ·»åŠ  action å ä½ç¬¦ + STOP token
3. **action embedding æ¸…é›¶**ï¼šå’Œè®­ç»ƒæ—¶ä¸€è‡´
4. **ä¸‰ç§é¢„æµ‹æ–¹å¼**ï¼šDiffusion / L1 å›å½’ / ç¦»æ•£ token
5. **åŠ¨ä½œåå½’ä¸€åŒ–**ï¼šä» [-1, 1] æ˜ å°„åˆ°çœŸå®æœºå™¨äººåŠ¨ä½œç©ºé—´
6. **LightVLA åŠ é€Ÿ**ï¼špruner åœ¨æ¨ç†æ—¶çœŸæ­£åˆ é™¤ patch token

---

åˆ°è¿™é‡Œï¼ŒLightVLA çš„ä¸»è¦æ¨¡å—éƒ½è®²è§£å®Œäº†ï¼ğŸ‰



### User Input

è®­ç»ƒå’Œæ¨ç†ï¼Œlightvlaæœ‰æ²¡æœ‰è®¾å®šä¿ç•™çš„æ¯”ä¾‹ï¼Ÿ

### Planner Response

å¥½é—®é¢˜ï¼è®©æˆ‘ç›´æ¥å›ç­”ï¼š

---

## ğŸ¯ LightVLA æœ‰æ²¡æœ‰è®¾å®šä¿ç•™æ¯”ä¾‹ï¼Ÿ

### ç­”æ¡ˆï¼š**æ²¡æœ‰å›ºå®šæ¯”ä¾‹ï¼** ä¿ç•™å¤šå°‘æ˜¯**åŠ¨æ€çš„**ï¼Œç”±æ¨¡å‹å­¦åˆ°çš„åˆ†æ•°å†³å®šã€‚

---

### ğŸ“Š è®­ç»ƒæ—¶

**å®Œå…¨ä¸å‰ªæ**ï¼Œåºåˆ—é•¿åº¦ä¿æŒä¸å˜ã€‚

```python
# train æ¨¡å¼ï¼Œåºåˆ—é•¿åº¦å§‹ç»ˆæ˜¯ P
patches = score @ patches  # è½¯èšåˆï¼Œé•¿åº¦ä¸å˜
```

---

### ğŸ“Š æ¨ç†æ—¶

**ä¿ç•™æ¯”ä¾‹ = `|unique(indices)| / P`**ï¼Œå®Œå…¨å–å†³äºæ¨¡å‹é¢„æµ‹çš„ [score](cci:1://file:///workspace/laiminxin/vla-opt/third_party/LightVLA/prismatic/extern/hf/modeling_prismatic.py:69:4-77:20)ã€‚

```python
# eval æ¨¡å¼
indices = score.argmax(dim=-1)  # (B, P)
# ä¾‹: indices = [0, 0, 0, 2, 2, 3, 3, 3]
# unique(indices) = {0, 2, 3}  â†’ ä¿ç•™ 3 ä¸ª

mask = [True, False, False, True, False, True, False, False]
# ä¿ç•™æ¯”ä¾‹ = 3/8 = 37.5%
```

**å…³é”®ä»£ç **ï¼ˆç¬¬ 80-90 è¡Œï¼‰ï¼š
```python
def score_to_mask(self, score):
    mask = torch.zeros(bsz, self.num_patches, dtype=torch.bool)
    indices = score.argmax(-1)  # æ¯ä¸ª patch æŒ‡å‘å“ªä¸ªç›®æ ‡
    mask[batch_indices, indices] = True  # è¢«æŒ‡å‘çš„æ‰ä¿ç•™
    return mask
```

---

### ğŸ¤” ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡ï¼Ÿ

| å›ºå®šæ¯”ä¾‹ï¼ˆå¦‚ä¿ç•™ 50%ï¼‰ | åŠ¨æ€æ¯”ä¾‹ï¼ˆLightVLAï¼‰ |
|------------------------|---------------------|
| ç®€å•ä½†å¯èƒ½ä¸¢ä¿¡æ¯ | æ ¹æ®å†…å®¹è‡ªé€‚åº” |
| ç®€å•åœºæ™¯å¯èƒ½ä¿ç•™å¤ªå¤š | ç®€å•åœºæ™¯åˆ æ›´å¤š |
| å¤æ‚åœºæ™¯å¯èƒ½ä¿ç•™å¤ªå°‘ | å¤æ‚åœºæ™¯åˆ æ›´å°‘ |

**ç›´è§‰**ï¼š
- å¦‚æœå›¾åƒå†…å®¹**ç®€å•**ï¼ˆå¤§ç‰‡å¤©ç©ºï¼‰ï¼Œå¾ˆå¤š patch ç›¸ä¼¼ â†’ `unique(indices)` å° â†’ åˆ æ›´å¤š
- å¦‚æœå›¾åƒå†…å®¹**å¤æ‚**ï¼ˆå¤šä¸ªç‰©ä½“ï¼‰ï¼Œpatch å„ä¸ç›¸åŒ â†’ `unique(indices)` å¤§ â†’ ä¿ç•™æ›´å¤š

---

### ğŸ“ˆ å®é™…ä¿ç•™æ¯”ä¾‹èŒƒå›´

æ ¹æ®è®ºæ–‡/å®éªŒï¼Œå…¸å‹çš„ä¿ç•™æ¯”ä¾‹åœ¨ **20%-40%** ä¹‹é—´ï¼Œä½†è¿™ä¸æ˜¯ç¡¬ç¼–ç çš„ï¼Œè€Œæ˜¯æ¨¡å‹è‡ªå·±å­¦åˆ°çš„ã€‚

```
åŸå§‹ patches: 512 (fused + 2 images)
å…¸å‹ä¿ç•™:     100-200
ä¿ç•™æ¯”ä¾‹:     ~20%-40%
```

